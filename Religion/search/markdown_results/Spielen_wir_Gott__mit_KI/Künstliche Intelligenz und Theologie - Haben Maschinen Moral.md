# [Künstliche Intelligenz und Theologie - Haben Maschinen Moral?](https://www.deutschlandfunkkultur.de/kuenstliche-intelligenz-und-theologie-haben-maschinen-moral-100.html)

Künstliche Intelligenz und Theologie - Haben Maschinen Moral? Deutschlandfunk Deutschlandfunk Nova LiveSeit 18:05 UhrNachspiel. FeatureLiveSeit 18:05 UhrNachspiel. Feature Programm Podcasts LiveSeit 18:05 UhrNachspiel. FeatureLiveSeit 18:05 UhrNachspiel. Feature Themen Bücher Meinung & Debatte Musik Film & Serie Politik Kulturnachrichten Psychologie Bühne Hörspiel + Feature Philosophie Umwelt Kakadu Leben Wissenschaft Geschichte Debatten und News aus der Kultur Instagram Programm Sendungen & Podcasts Musikliste Archiv Deutschlandfunk Deutschlandfunk Nova Archiv Künstliche Intelligenz und Theologie Haben Maschinen Moral? 41:47 Minuten Die Maschine denkt, Gott lenkt? Das sieht der Theologe Matthias Braun anders: Die Verantwortung für Künstliche Intelligenz trage am Ende der Mensch. © Dr. Matthias Braun Matthias Braun im Gespräch mit Thorsten Jabs · 31.03.2019 Twitter Facebook Email Pocket Audio herunterladen Im Wissenschaftsjahr 2019 steht die Künstliche Intelligenz im Mittelpunkt. Wir fragen den Theologen Matthias Braun, welche Rolle Begriffe wie Gefühl, Bewusstsein und Seele dabei spielen und ob der Gott der Zukunft ein Computer sein kann. Aus dem PodcastReligionen Podcast abonnieren Podcast hören PodcastReligionen Überirdisch und überaus irdisch – Glaube prägt ganze Gesellschaften. In „Religionen“ erfahren Sie... Mehr anzeigen Ganze Sendung Beitrag Apple Podcasts RSS Feed Alle Podcasts anzeigen Thorsten Jabs: "Wir wollen die Chancen, die Künstliche Intelligenz birgt, erkennen und ergreifen. Wissenschaft und Forschung sind wichtige Treiber, damit dies gelingt." Mit diesen Worten hatte Bundesbildungsministerin Anja Karliczek in der vergangenen Woche das Wissenschaftsjahr 2019 mit dem Schwerpunkt Künstliche Intelligenz eröffnet. Dabei sind Natur und Sozialwissenschaftler gleichermaßen gefordert und damit natürlich auch die Theologie. Schließlich geht es um ethische und philosophische Fragen, die religiöse Grundgedanken berühren. Theologie und Technik Darüber spreche ich jetzt mit dem Theologen Matthias Braun von der Friedrich-Alexander-Universität Erlangen-Nürnberg. Herr Braun, wie bewertet die Theologie derzeit die Künstliche Intelligenz? Ist sie etwas Göttliches, weil Gott den Menschen und der Mensch wiederum die KI geschaffen hat? Braun: Zunächst einmal ist Künstliche Intelligenz eine Technologie: etwas, was unser Leben, die Art und Weise, wie wir leben, ermöglicht, was sie gleichzeitig durchdringt und was dann auch bestimmte Möglichkeiten für Handeln schafft und gleichzeitig vielleicht auch gewisse Schwierigkeiten und Herausforderungen mit sich bringt. Aber sie ist etwas, was Menschen gemacht haben, was Menschen steuern, und ich würde sagen, was Menschen dann auch verantworten. Wenn wir als Theologen über Big Data, Künstliche Intelligenz nachdenken, dann kommt noch eine Ebene mit hinzu, das ist nämlich die Frage: Was macht eigentlich den Mensch als Menschen aus, und wie verändern sich vielleicht auch die Vorstellungen von Menschen, vom Menschsein durch solche Technologien, wie zum Beispiel die Künstliche Intelligenz? Verantwortung trägt der Mensch Da ist die Antwort gerade auch der protestantischen Theologie zunächst einmal, dass sie sagt: Der Mensch ist oder glaubt sich als ein von Gott Geschaffener und damit immer schon in einer Verantwortungs-, Antwortungssituation Stehender. Das, würde ich sagen, ist erst mal der unterschiedliche Ausgangspunkt, wenn ein Theologe über eine Technologie nachdenkt - anders als ein Philosoph, ein Soziologe, ein Politikwissenschaftler oder wer auch immer. Jabs: Muss aus der theologischen Sicht der Mensch dann quasi ethische Grundsätze an die KI weitergeben, weil er sie programmiert? Braun: Also weitergeben, da müssten wir uns jetzt drüber unterhalten, wie wir das meinen. Ich glaube, das Entscheidende wäre erst mal, dass wir eine Verantwortung haben für das, was wir tun. Das heißt auch, dass wir eine Verantwortung haben für das, was wir nicht tun, und wenn die Theologie den Menschen als einen von Gott Geschaffenen versteht, dann muss man, glaube ich, mit hinnehmen, dass wir in der Theologie zwei Figuren haben, die dann entscheidend sind. Das ist zum einen die Idee, das Verständnis, dass der Mensch ein von Gott geschaffenes Wesen ist und damit ein Mensch ist, der nach seinem Bilde geschaffen ist, also wir nennen das dann die Gottesebenbildlichkeit oder auch säkular gesprochen: die Figur der Menschenwürde. Was sollen wir tun, was dürfen wir lassen? Das zweite Wesentliche ist aber, dass dieser Mensch ein Mensch ist, der Würde hat, aber gerade als ein würdevoll angesprochen Seiender auch ein verletzliches Wesen ist. Ich glaube, dass diese Verletzlichkeit, diese Verwundbarkeit des Menschen auch das ist, was ganz besonders in Betracht kommt, wenn wir über solche Technologien wie die Künstliche Intelligenz nachdenken. An welchen Stellen ermöglicht sie neue Freiheitsgewinne, und an welchen Stellen verschließt sie vielleicht oder verunmöglicht auch bestimmte Freiheitsvollzüge für einzelne Individuen, auch für Individuen, die miteinander leben wollen? Insofern würde ich sagen, ist die Aufgabe der Theologie an der Stelle, darüber nachzudenken: Wie kann ein verantwortlicher Umgang mit solchen neuen Technologien aussehen? Wie kann die Künstliche Intelligenz, die gerade sehr präsent in den Medien und in den wissenschaftlichen Debatten ist, verantwortlich gestaltet werden? Und das heißt: sowohl in Bezug auf das, was wir tun, aber auch auf das, was wir nicht tun, was wir unterlassen. Frankensteins Mahnung - Geschöpfe des Menschen Jabs: Wenn man sich mit philosophischen Fragen der KI beschäftigt, stößt man des Öfteren auf Geschichten zum Beispiel von Frankensteins Monster oder den Golem der jüdischen Mystik. Das sind Figuren, die der Mensch erschaffen hat, die sich aber gegen ihren Schöpfer wenden. Lassen sich da Parallelen zur KI beziehungsweise zum Verhältnis zwischen Theologie und KI ziehen? Braun: Zur Ehrlichkeit gehört dazu, dass wir Menschen dazu neigen, erst mal mit jeglicher Form von Technologie bestimmte Redeweisen, bestimmte Sprachformen zu finden, um das irgendwie zu deuten. Das hat ja auch etwas damit zu tun, dass wir, glaube ich, alle sofort intuitiv realisieren: Das hat etwas unmittelbar mit uns zu tun, das hat etwas unmittelbar mit der Art und Weise zu tun, wie wir miteinander leben. Was Sie jetzt angesprochen haben mit dem Golem, mit Frankenstein, das ist ja interessanterweise etwas, was wir in vielen Bereichen diskutieren, zum Beispiel in der Biotechnologie, der synthetischen Biologie: Darf und kann man aus anorganischer Materie organische Materie machen? Kann man so etwas wie Leben aus dem Nichts erschaffen? Da spielen diese Fragen auch eine sehr, sehr große Rolle, vielleicht sogar noch stärker als jetzt im Bereich der Künstlichen Intelligenz. Sind Maschinen fähig zu Moral? Was wir im Bereich der Künstlichen Intelligenz vielleicht eher haben, ist diese Frage: Haben Maschinen so etwas wie Moral? Können sie so etwas wie Formen von Bewusstsein von vielleicht auch Gefühlen entwickeln? Ich glaube, das sind Fragen, die vielleicht eher im Bereich der Künstlichen Intelligenz eine ganz große Rolle spielen. Wo ich Ihnen aber zustimmen würde, ist der Punkt, zu sagen, dass beides an vielen Stellen auch erst mal, glaube ich, mit großen Sorgen und vielleicht auch mit gewissen Ängsten besetzt ist, vielleicht gerade bei uns in Deutschland. Wenn man sich da aktuelle Studien anschaut, dann sieht man, dass wir in Deutschland vielleicht besonders ängstlich an solche neuen Technologien herangehen und an vielen Stellen sicherlich auch sehr begründete Sorgen haben. Wenn wir uns zum Beispiel angucken: Was wird Künstliche Intelligenz mit Arbeitsplätzen machen? Wozu führt die Automatisierung, wenn immer mehr Arbeitsprozesse, wie wir sie kennen, wie sie uns vertraut sind und wie sie ja für viele Menschen auch eine wichtige Lebensgrundlage sind, wenn die dann automatisiert werden? Dann sind das ja ganz konkrete Fragen auf einmal, wo man sagt, ja, da hat diese Sorge vielleicht auf einmal einen realen Anlass. Dennoch würde ich sagen, ist es so diese grundlegende Sorge, dass da etwas mit der Art und Weise passiert, wie wir leben, ist erst mal etwas, was mit Technologie als solcher mir sehr eng verbunden scheint, und an vielen Stellen können wir das beobachten. Nicht Mensch, nicht Gott: Engel, Tiere, Apparate Jabs: Das berührt ja auch sehr die Science Fiction. Wird in der Theologie auch darüber gedacht, ob Künstliche Intelligenz so etwas wie Bewusstsein, so wie Sie es sagen, Gefühl, also auch Seele haben kann? Braun: Na ja, das ist eine spannende Frage. Wenn ich ein bisschen ausholen darf, würde ich zunächst mal sagen, theologisch können wir uns das sehr einfach machen, und dann können wir erst mal sagen: Na ja, Bewusstsein, Verantwortung in besonderer Weise hat der Mensch, der Mensch als ein von Gott Geschaffener, und damit in einer bestimmten Verantwortungsposition Stehender. Dann wird es aber interessant, weil wenn ich mir dann angucke, wie denkt die Theologie denn auch über andere Formen von Wesen, über andere Formen von vielleicht auch, ein Philosoph hat mal das Wort vorgeschlagen: von Aktanten, also Wesen, wo wir sagen, die sind weder einfach reine Objekte noch sind die irgendwie reine Subjekte, sondern irgendwie changieren die so dazwischen. Dann gibt es ja zum Beispiel die Lehre von den Engeln oder ganz praktisch gesagt: Wie ist es eigentlich mit den Tieren. Das sind Formen von Akteuren, die sozusagen in bestimmten Bereichen ja auch Handlungen ausüben, die auch in bestimmten Beziehungen zu uns stehen, wo wir vielleicht auch sagen würden, na ja, die zeigen Formen von Bewusstsein. Also, das heißt, diese Idee, dieser Streit, dieses Ringen darum, ist es eigentlich nur der Mensch, der jetzt Bewusstsein hat, der fühlt, der in bestimmter Verantwortung steht, wird einerseits klar beantwortet: Ja, es ist der Mensch, der nachher Verantwortung hat. Gleichzeitig gibt es aber ein Nachdenken darüber: Wie ist das eigentlich mit anderen Formen von Wesen, von Aktanten, welche Form von Bewusstsein, welche Form von vielleicht auch Subjekthaftigkeit haben die oder können die vielleicht auch einnehmen? Die Zukunft hat schon begonnen Jabs: Das Bild von Künstlicher Intelligenz ist in den letzten Jahrzehnten auch sehr durch Science-Fiction-Filme geprägt worden, von "2001: Odyssee im Weltraum" über "Star Trek" bis hin zu "Terminator", in dem Künstliche Intelligenz die Weltherrschaft übernimmt. Für den Historiker Yuval Noah Harari sind die Filme über KI weit entfernt von wissenschaftlicher Realität. Geben Sie ihm recht? Braun: Na ja, ich würde jetzt sagen, in dem neuen Werk, "21 Lektionen", von Harari, aber auch schon in "Homo Deus", da ist es ja so, dass Harari da doch auch differenziert. Also einerseits sagt er, wir haben irgendwie so ein romantisierendes, vielleicht auch teilweise veraltetes Verständnis von Künstlicher Intelligenz, aber gleichzeitig gibt es dann auch in den ganz aktuellen Filmen viel, wo ich sagen würde, das ist gar nicht weit weg von der Realität. Denken Sie beispielsweise an den Film "Her", wo ja der Protagonist so eine Art Beziehung – da ist ja schon die Frage, was ist das, ist das eine Liebesbeziehung, ist das irgendwie eine freundschaftliche Beziehung – mit dieser sprachgesteuerten Software eingeht. Bei "Ex Machina" ist auch die Idee: Da sind irgendwie Wesen, die vielleicht maschinenartig aussehen, aber die so etwas wie Gefühle haben können. Alexa, was sagst du dazu? Also ich glaube, die Frage Gefühle, Bewusstsein ist in der Tat eine Schwelle, wo wir an der Stelle jetzt erst mal sagen müssen, nach aktuellem Stand gibt es keine Künstliche Intelligenz, wo wir jetzt mit guten Gründen davon ausgehen würden, dass die etwas fühlt oder dass die so etwas wie Bewusstsein aufzeigt. Aber andererseits, wenn wir jetzt zum Beispiel über unsere Sprachassistenten Alexa, Siri, wer auch immer sozusagen da der Favorit ist, nachdenken, dann merken wir: Das sind ja schon Formen von Künstlicher Intelligenz, die sich sehr, sehr tief in unsere Lebensvollzüge eingeschrieben haben. Es mag Leute geben, die mit Ihrem Smartphone oder mit diesem Assistenten vielleicht sogar mehr reden als mit realen Menschen. Also, von daher – und das ist auch etwas, was Harari beobachtet - ich glaube schon, dass Künstliche Intelligenz mittlerweile so sehr Bestandteil unserer Lebenswirklichkeit ist, dass wir uns etwas vormachen, wenn wir so tun, als wäre das alles einfach ganz weit weg. Ist Gott ein Geist aus der Maschine? Ich glaube, dass jeder Hörer, jede Hörerin, dass Sie, dass ich sehr, sehr viel mit diesen Technologien bereits zu tun haben, was aber auch der Grund dafür ist, dass wir uns zum einen so sehr dafür interessieren, aber manchmal vielleicht auch vergessen, ganz nüchtern auf das zu schauen, was es denn dann tatsächlich ist. Jabs: Vor etwa anderthalb Jahren wurde berichtet, dass der Unternehmer und ehemalige Google-Entwickler Anthony Levandowski eine Kirche gegründet hat und jetzt ihren Erlöser mithilfe von Computercodes erschaffen will. Er wird mit den Worten zitiert: "Wenn etwas eine Milliarde mal klüger ist als der klügste Mensch, wie soll man solch eine Instanz anders nennen als Gott?" Kann die Künstliche Intelligenz der Gott der Zukunft sein für manche Menschen und damit auch eine Gefahr für die Religion? Braun: Heute holen Sie aber ganz, ganz spannende Fragen raus! Also würde ich jetzt erst mal, wenn ich so kurz drüber nachdenke, sagen, ich glaube nein, aber ich sage ganz kurz, warum ich nein sage, und vielleicht schränke ich das danach noch mal ein. Jabs: Gerne! Braun: Also, zunächst einmal würde ich sagen, der Gott, den jetzt zumindest aus einer christlich-theologischen Perspektive die Bibel bezeugt, der ist ja einer, der sich nicht dadurch auszeichnet, dass er sich ständig als der Klügste, als der Stärkste, als der Beste, als der was auch immer Gelagerte, Höchste auszeichnen muss, sondern das ist ja ein sehr empathischer Gott. Das ist ja ein Gott, der mitfühlt, der Beziehungen mit seinem Volk, mit dann einzelnen Menschen eingeht, der zu ihnen steht, der mit ihnen leidet. Die stille Macht der Dinge Das ist natürlich auch ein Gott, der etwas schafft, der sozusagen durch Macht gekennzeichnet ist und sich auszeichnet, aber ich glaube, diese Vorstellung zu sagen, Gott ist einfach nur das höchste Prinzip oder das größte dessen, was wir uns irgendwie vorstellen können, ist sicherlich auch eine wichtige Dimension, aber aus einer christlich-theologischen Perspektive nicht die einzig adäquate Beschreibung, wenn wir über Gott nachdenken. Und doch glaube ich – das wäre jetzt sozusagen das Aber –, dass, wenn man darüber nachdenkt, wir natürlich dieser Form von Künstlicher Intelligenz auch ein sehr großes Gewicht oder sehr großen Raum einräumen. Es gibt auch in der christlichen Theologie ein sehr intensives Nachdenken darüber, wie viel Macht eigentlich Gegenstände oder auch Technologien über unser Leben bekommen können und ob das dann noch ein gesunder und ein guter Zugang ist oder nicht. Wenn ich eine sehr unpopuläre Figur, die auch in der theologischen Debatte nicht so ganz gerne gesehen wird, da mal ins Spiel bringen darf, dann würde man vielleicht theologisch sagen können, dass das eine Form von Sünde sein kann. Wir nennen das in der Theologie Hamartia-Theologie, also: die Lehre von der Sünde. Technikgläubigkeit als Sünde Ich glaube, dass eine bestimmte Gläubigkeit an so etwas wie Künstliche Intelligenz - der Glaube, dass das die alles umfassende Lösung ist - zu einer Zielverfehlung führt, also dazu führt, dass wir nicht mehr darüber nachdenken: wie können wir verantwortlich Lebensvollzüge gestalten, individuelle Freiheitsräume ermöglichen und dann auch zu einem gemeinwohlorientierten Gemeinschaftsverständnis kommen, sondern dass man nur noch auf die Technologie als Technologie schaut und versucht, in irgendwelchen wilden spekulativen Ideen diese Technologie maßlos zu überhöhen. Ich glaube, immer dann, wenn man versucht, eine Technologie alleine als Technologie zu bewerten, zu beschreiben, vielleicht auch sogar zu vergöttern, wie Sie es jetzt gerade angedeutet haben, dann führt das zu einer Zielverfehlung. Dann führt das dazu, dass wir nicht mehr in einer gesunden Art und Weise mit dieser Technologie umgehen und auch nicht mehr in einer gesunden Art und Weise über die Gestaltungsräume nachdenken. Theologische Ethik – nüchtern und kühn Jabs: Und was muss eine theologische Ethik aus Ihrer Sicht leisten, die sich mit Künstlicher Intelligenz beschäftigt? Braun: Ich finde da eigentlich zwei Punkte sehr, sehr wichtig, die der Theologe Dietrich Bonhoeffer mal vorgeschlagen hat, dass das doch Prinzipien sein könnten, die theologisches Nachdenken leiten sollten, und zwar zum einen, dass eine theologische Ethik erst mal sehr nüchtern ist. Nüchtern heißt an der Stelle erst mal, dass die sehr sorgsam unterscheidet, dass die sehr sorgsam differenziert. Ethik, so würde ich sagen, ist erst mal die Kunst der Unterscheidung, das ist, sehr genau hinzugucken, welche Effekte hat eine Technologie in einem bestimmten Kontext. Das Zweite – und das ist vielleicht etwas, was wir als Theologen wirklich auch in die Debatte einbringen können – ist erst mal eine gewisse Kühnheit – so hat Bonhoeffer das genannt –, und Kühnheit heißt ja auch, einen gewissen Wagemut, eine gewisse Hoffnungsfroheit. Das heißt nicht, dass wir immer optimistisch sind, aber das heißt, dass wir uns die Hoffnung nicht rauben lassen und dass wir aus dieser Haltung heraus die Gestaltung solcher Herausforderungen angehen. Äußerungen unserer Gesprächspartner geben deren eigene Auffassungen wieder. Deutschlandfunk Kultur macht sich Äußerungen seiner Gesprächspartner in Interviews und Diskussionen nicht zu eigen. Mehr zum Thema Volker Jung: „Digital Mensch bleiben“ Digitale Glaubensfragen Mensch und Maschine Ohne Bewusstsein keine Intelligenz Künstliche Intelligenz Die Roboter kommen näher Zur Startseite Entdecken Sie Deutschlandfunk Kultur Programm Vorschau und Rückschau Sendungen und Podcasts Musikliste Kakadu – Das Kinderprogramm Korrekturen und Richtigstellungen Archiv Hören Livestream Frequenzen (UKW + DAB+) Service FAQ Apps Newsletter RSS Veranstaltungen Kontakt Hörerservice Social Media Über uns Deutschlandradio Presse Karriere Entdecken Sie Deutschlandfunk Kultur Programm Vorschau und Rückschau Sendungen und Podcasts Musikliste Kakadu – Das Kinderprogramm Korrekturen und Richtigstellungen Archiv Hören Livestream Frequenzen (UKW + DAB+) Service FAQ Apps Newsletter RSS Veranstaltungen Kontakt Hörerservice Social Media Über uns Deutschlandradio Presse Karriere Deutschlandradio © 2024 Datenschutzerklärung Nutzungsbedingungen Impressum Partner ARD| ZDF| Phoenix| arte| Chronik der Mauer