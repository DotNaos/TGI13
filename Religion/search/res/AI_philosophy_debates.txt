Titel: ERROR: The request could not be satisfied

ERROR: The request could not be satisfied 403 ERROR The request could not be satisfied. Request blocked. We can't connect to the server for this app or website at this time. There might be too much traffic or a configuration error. Try again later, or contact the app or website owner. If you provide content to customers through CloudFront, you can find steps to troubleshoot and help prevent this error by reviewing the CloudFront documentation. Generated by cloudfront (CloudFront) Request ID: p5nIhsfk1NKylMdqhVJ1mLEzG9g-zfF9Gil0WuT6zd8BsTUeEwcZ1g==

Titel: Philosophy of artificial intelligence - Wikipedia

Philosophy of artificial intelligence - Wikipedia Jump to content Main menu Main menu move to sidebar hide Navigation Main pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate Contribute HelpLearn to editCommunity portalRecent changesUpload file Search Search Create account Log in Personal tools Create account Log in Pages for logged out editors learn more ContributionsTalk Contents move to sidebar hide (Top) 1Can a machine display general intelligence? Toggle Can a machine display general intelligence? subsection 1.1Intelligence 1.1.1Turing test 1.1.2Intelligence as achieving goals 1.2Arguments that a machine can display general intelligence 1.2.1The brain can be simulated 1.2.2Human thinking is symbol processing 1.2.3Arguments against symbol processing 1.2.3.1Gödelian anti-mechanist arguments 1.2.3.2Dreyfus: the primacy of implicit skills 2Can a machine have a mind, consciousness, and mental states? Toggle Can a machine have a mind, consciousness, and mental states? subsection 2.1Consciousness, minds, mental states, meaning 2.2Arguments that a computer cannot have a mind and mental states 2.2.1Searle's Chinese room 2.2.2Related arguments: Leibniz' mill, Davis's telephone exchange, Block's Chinese nation and Blockhead 2.2.3Responses to the Chinese room 3Is thinking a kind of computation? 4Other related questions Toggle Other related questions subsection 4.1Can a machine have emotions? 4.2Can a machine be self-aware? 4.3Can a machine be original or creative? 4.4Can a machine be benevolent or hostile? 4.5Can a machine imitate all human characteristics? 4.6Can a machine have a soul? 5Views on the role of philosophy 6Conferences and literature 7See also 8Notes 9References Toggle References subsection 9.1Works cited Toggle the table of contents Philosophy of artificial intelligence 24 languages AfrikaansالعربيةAzərbaycancaCatalàČeštinaΕλληνικάEspañolفارسیFrançais한국어ՀայերենBahasa IndonesiaپښتوPolskiPortuguêsРусскийکوردیSvenskaதமிழ்TürkçeУкраїнськаTiếng Việt粵語中文 Edit links ArticleTalk English ReadEditView history Tools Tools move to sidebar hide Actions ReadEditView history General What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR codeWikidata item Print/export Download as PDFPrintable version From Wikipedia, the free encyclopedia Overview of the philosophy of artificial intelligence See also: Ethics of artificial intelligence Part of a series onArtificial intelligence Major goals Artificial general intelligence Recursive self-improvement Planning Computer vision General game playing Knowledge reasoning Machine learning Natural language processing Robotics AI safety Approaches Symbolic Deep learning Bayesian networks Evolutionary algorithms Situated approach Hybrid intelligent systems Systems integration Applications Projects Deepfake Machine translation Generative AI Art Audio Music Healthcare Mental health Government Industry Earth sciences Bioinformatics Physics Philosophy Chinese room Friendly AI Control problem/Takeover Ethics Existential risk Turing test Regulation History Timeline Progress AI winter AI boom AI era Glossary Glossary vte The philosophy of artificial intelligence is a branch of the philosophy of mind and the philosophy of computer science[1] that explores artificial intelligence and its implications for knowledge and understanding of intelligence, ethics, consciousness, epistemology, and free will.[2][3] Furthermore, the technology is concerned with the creation of artificial animals or artificial people (or, at least, artificial creatures; see artificial life) so the discipline is of considerable interest to philosophers.[4] These factors contributed to the emergence of the philosophy of artificial intelligence. The philosophy of artificial intelligence attempts to answer such questions as follows:[5] Can a machine act intelligently? Can it solve any problem that a person would solve by thinking? Are human intelligence and machine intelligence the same? Is the human brain essentially a computer? Can a machine have a mind, mental states, and consciousness in the same sense that a human being can? Can it feel how things are? (i.e does it have qualia?) Questions like these reflect the divergent interests of AI researchers, cognitive scientists and philosophers respectively. The scientific answers to these questions depend on the definition of "intelligence" and "consciousness" and exactly which "machines" are under discussion. Important propositions in the philosophy of AI include some of the following: Turing's "polite convention": If a machine behaves as intelligently as a human being, then it is as intelligent as a human being.[6] The Dartmouth proposal: "Every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it."[7] Allen Newell and Herbert A. Simon's physical symbol system hypothesis: "A physical symbol system has the necessary and sufficient means of general intelligent action."[8] John Searle's strong AI hypothesis: "The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds."[9] Hobbes' mechanism: "For 'reason' ... is nothing but 'reckoning,' that is adding and subtracting, of the consequences of general names agreed upon for the 'marking' and 'signifying' of our thoughts..."[10] Can a machine display general intelligence?[edit] Is it possible to create a machine that can solve all the problems humans solve using their intelligence? This question defines the scope of what machines could do in the future and guides the direction of AI research. It only concerns the behavior of machines and ignores the issues of interest to psychologists, cognitive scientists and philosophers, evoking the question: does it matter whether a machine is really thinking, as a person thinks, rather than just producing outcomes that appear to result from thinking?[11] The basic position of most AI researchers is summed up in this statement, which appeared in the proposal for the Dartmouth workshop of 1956: "Every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it."[7] Arguments against the basic premise must show that building a working AI system is impossible because there is some practical limit to the abilities of computers or that there is some special quality of the human mind that is necessary for intelligent behavior and yet cannot be duplicated by a machine (or by the methods of current AI research). Arguments in favor of the basic premise must show that such a system is possible. It is also possible to sidestep the connection between the two parts of the above proposal. For instance, machine learning, beginning with Turing's infamous child machine proposal,[12] essentially achieves the desired feature of intelligence without a precise design-time description as to how it would exactly work. The account on robot tacit knowledge[13] eliminates the need for a precise description altogether. The first step to answering the question is to clearly define "intelligence". Intelligence[edit] The "standard interpretation" of the Turing test[14] Turing test[edit] Main article: Turing test Alan Turing[15] reduced the problem of defining intelligence to a simple question about conversation. He suggests that: if a machine can answer any question posed to it, using the same words that an ordinary person would, then we may call that machine intelligent. A modern version of his experimental design would use an online chat room, where one of the participants is a real person and one of the participants is a computer program. The program passes the test if no one can tell which of the two participants is human.[6] Turing notes that no one (except philosophers) ever asks the question "can people think?" He writes "instead of arguing continually over this point, it is usual to have a polite convention that everyone thinks".[16] Turing's test extends this polite convention to machines: If a machine acts as intelligently as a human being, then it is as intelligent as a human being. One criticism of the Turing test is that it only measures the "humanness" of the machine's behavior, rather than the "intelligence" of the behavior. Since human behavior and intelligent behavior are not exactly the same thing, the test fails to measure intelligence. Stuart J. Russell and Peter Norvig write that "aeronautical engineering texts do not define the goal of their field as 'making machines that fly so exactly like pigeons that they can fool other pigeons'".[17] Intelligence as achieving goals[edit] Simple reflex agent Twenty-first century AI research defines intelligence in terms of goal-directed behavior. It views intelligence as a set of problems that the machine is expected to solve – the more problems it can solve, and the better its solutions are, the more intelligent the program is. AI founder John McCarthy defined intelligence as "the computational part of the ability to achieve goals in the world."[18] Stuart Russell and Peter Norvig formalized this definition using abstract intelligent agents. An "agent" is something which perceives and acts in an environment. A "performance measure" defines what counts as success for the agent.[19] "If an agent acts so as to maximize the expected value of a performance measure based on past experience and knowledge then it is intelligent."[20] Definitions like this one try to capture the essence of intelligence. They have the advantage that, unlike the Turing test, they do not also test for unintelligent human traits such as making typing mistakes.[21] They have the disadvantage that they can fail to differentiate between "things that think" and "things that do not". By this definition, even a thermostat has a rudimentary intelligence.[22] Arguments that a machine can display general intelligence[edit] The brain can be simulated[edit] Main article: Artificial brain An MRI scan of a normal adult human brain Hubert Dreyfus describes this argument as claiming that "if the nervous system obeys the laws of physics and chemistry, which we have every reason to suppose it does, then ... we ... ought to be able to reproduce the behavior of the nervous system with some physical device".[23] This argument, first introduced as early as 1943[24] and vividly described by Hans Moravec in 1988,[25] is now associated with futurist Ray Kurzweil, who estimates that computer power will be sufficient for a complete brain simulation by the year 2029.[26] A non-real-time simulation of a thalamocortical model that has the size of the human brain (1011 neurons) was performed in 2005,[27] and it took 50 days to simulate 1 second of brain dynamics on a cluster of 27 processors. Even AI's harshest critics (such as Hubert Dreyfus and John Searle) agree that a brain simulation is possible in theory.[a] However, Searle points out that, in principle, anything can be simulated by a computer; thus, bringing the definition to its breaking point leads to the conclusion that any process at all can technically be considered "computation". "What we wanted to know is what distinguishes the mind from thermostats and livers," he writes.[30] Thus, merely simulating the functioning of a living brain would in itself be an admission of ignorance regarding intelligence and the nature of the mind, like trying to build a jet airliner by copying a living bird precisely, feather by feather, with no theoretical understanding of aeronautical engineering.[31] Human thinking is symbol processing[edit] Main article: Physical symbol system In 1963, Allen Newell and Herbert A. Simon proposed that "symbol manipulation" was the essence of both human and machine intelligence. They wrote: "A physical symbol system has the necessary and sufficient means of general intelligent action."[8] This claim is very strong: it implies both that human thinking is a kind of symbol manipulation (because a symbol system is necessary for intelligence) and that machines can be intelligent (because a symbol system is sufficient for intelligence).[32] Another version of this position was described by philosopher Hubert Dreyfus, who called it "the psychological assumption": "The mind can be viewed as a device operating on bits of information according to formal rules."[33] The "symbols" that Newell, Simon and Dreyfus discussed were word-like and high level—symbols that directly correspond with objects in the world, such as and . Most AI programs written between 1956 and 1990 used this kind of symbol. Modern AI, based on statistics and mathematical optimization, does not use the high-level "symbol processing" that Newell and Simon discussed. Arguments against symbol processing[edit] These arguments show that human thinking does not consist (solely) of high level symbol manipulation. They do not show that artificial intelligence is impossible, only that more than symbol processing is required. Gödelian anti-mechanist arguments[edit] Main article: Mechanism (philosophy): Gödelian arguments In 1931, Kurt Gödel proved with an incompleteness theorem that it is always possible to construct a "Gödel statement" that a given consistent formal system of logic (such as a high-level symbol manipulation program) could not prove. Despite being a true statement, the constructed Gödel statement is unprovable in the given system. (The truth of the constructed Gödel statement is contingent on the consistency of the given system; applying the same process to a subtly inconsistent system will appear to succeed, but will actually yield a false "Gödel statement" instead.)[citation needed] More speculatively, Gödel conjectured that the human mind can correctly eventually determine the truth or falsity of any well-grounded mathematical statement (including any possible Gödel statement), and that therefore the human mind's power is not reducible to a mechanism.[34] Philosopher John Lucas (since 1961) and Roger Penrose (since 1989) have championed this philosophical anti-mechanist argument.[35] Gödelian anti-mechanist arguments tend to rely on the innocuous-seeming claim that a system of human mathematicians (or some idealization of human mathematicians) is both consistent (completely free of error) and believes fully in its own consistency (and can make all logical inferences that follow from its own consistency, including belief in its Gödel statement)[citation needed]. This is provably impossible for a Turing machine to do (see Halting problem); therefore, the Gödelian concludes that human reasoning is too powerful to be captured by a Turing machine, and by extension, any digital mechanical device. However, the modern consensus in the scientific and mathematical community is that actual human reasoning is inconsistent; that any consistent "idealized version" H of human reasoning would logically be forced to adopt a healthy but counter-intuitive open-minded skepticism about the consistency of H (otherwise H is provably inconsistent); and that Gödel's theorems do not lead to any valid argument that humans have mathematical reasoning capabilities beyond what a machine could ever duplicate.[36][37][38] This consensus that Gödelian anti-mechanist arguments are doomed to failure is laid out strongly in Artificial Intelligence: "any attempt to utilize (Gödel's incompleteness results) to attack the computationalist thesis is bound to be illegitimate, since these results are quite consistent with the computationalist thesis."[39] Stuart Russell and Peter Norvig agree that Gödel's argument does not consider the nature of real-world human reasoning. It applies to what can theoretically be proved, given an infinite amount of memory and time. In practice, real machines (including humans) have finite resources and will have difficulty proving many theorems. It is not necessary to be able to prove everything in order to be an intelligent person.[40] Less formally, Douglas Hofstadter, in his Pulitzer prize winning book Gödel, Escher, Bach: An Eternal Golden Braid, states that these "Gödel-statements" always refer to the system itself, drawing an analogy to the way the Epimenides paradox uses statements that refer to themselves, such as "this statement is false" or "I am lying".[41] But, of course, the Epimenides paradox applies to anything that makes statements, whether they are machines or humans, even Lucas himself. Consider: Lucas can't assert the truth of this statement.[42] This statement is true but cannot be asserted by Lucas. This shows that Lucas himself is subject to the same limits that he describes for machines, as are all people, and so Lucas's argument is pointless.[43] After concluding that human reasoning is non-computable, Penrose went on to controversially speculate that some kind of hypothetical non-computable processes involving the collapse of quantum mechanical states give humans a special advantage over existing computers. Existing quantum computers are only capable of reducing the complexity of Turing computable tasks and are still restricted to tasks within the scope of Turing machines.[citation needed][clarification needed]. By Penrose and Lucas's arguments, the fact that quantum computers are only able to complete Turing computable tasks implies that they cannot be sufficient for emulating the human mind.[citation needed] Therefore, Penrose seeks for some other process involving new physics, for instance quantum gravity which might manifest new physics at the scale of the Planck mass via spontaneous quantum collapse of the wave function. These states, he suggested, occur both within neurons and also spanning more than one neuron.[44] However, other scientists point out that there is no plausible organic mechanism in the brain for harnessing any sort of quantum computation, and furthermore that the timescale of quantum decoherence seems too fast to influence neuron firing.[45] Dreyfus: the primacy of implicit skills[edit] Main article: Hubert Dreyfus's views on artificial intelligence Hubert Dreyfus argued that human intelligence and expertise depended primarily on fast intuitive judgements rather than step-by-step symbolic manipulation, and argued that these skills would never be captured in formal rules.[46] Dreyfus's argument had been anticipated by Turing in his 1950 paper Computing machinery and intelligence, where he had classified this as the "argument from the informality of behavior."[47] Turing argued in response that, just because we do not know the rules that govern a complex behavior, this does not mean that no such rules exist. He wrote: "we cannot so easily convince ourselves of the absence of complete laws of behaviour ... The only way we know of for finding such laws is scientific observation, and we certainly know of no circumstances under which we could say, 'We have searched enough. There are no such laws.'"[48] Russell and Norvig point out that, in the years since Dreyfus published his critique, progress has been made towards discovering the "rules" that govern unconscious reasoning.[49] The situated movement in robotics research attempts to capture our unconscious skills at perception and attention.[50] Computational intelligence paradigms, such as neural nets, evolutionary algorithms and so on are mostly directed at simulated unconscious reasoning and learning. Statistical approaches to AI can make predictions which approach the accuracy of human intuitive guesses. Research into commonsense knowledge has focused on reproducing the "background" or context of knowledge. In fact, AI research in general has moved away from high level symbol manipulation, towards new models that are intended to capture more of our intuitive reasoning.[49] Cognitive science and psychology eventually came to agree with Dreyfus' description of human expertise. Daniel Kahnemann and others developed a similar theory where they identified two "systems" that humans use to solve problems, which he called "System 1" (fast intuitive judgements) and "System 2" (slow deliberate step by step thinking).[51] Although Dreyfus' views have been vindicated in many ways, the work in cognitive science and in AI was in response to specific problems in those fields and was not directly influenced by Dreyfus. Historian and AI researcher Daniel Crevier wrote that "time has proven the accuracy and perceptiveness of some of Dreyfus's comments. Had he formulated them less aggressively, constructive actions they suggested might have been taken much earlier."[52] Can a machine have a mind, consciousness, and mental states?[edit] This is a philosophical question, related to the problem of other minds and the hard problem of consciousness. The question revolves around a position defined by John Searle as "strong AI": A physical symbol system can have a mind and mental states.[9] Searle distinguished this position from what he called "weak AI": A physical symbol system can act intelligently.[9] Searle introduced the terms to isolate strong AI from weak AI so he could focus on what he thought was the more interesting and debatable issue. He argued that even if we assume that we had a computer program that acted exactly like a human mind, there would still be a difficult philosophical question that needed to be answered.[9] Neither of Searle's two positions are of great concern to AI research, since they do not directly answer the question "can a machine display general intelligence?" (unless it can also be shown that consciousness is necessary for intelligence). Turing wrote "I do not wish to give the impression that I think there is no mystery about consciousness… [b]ut I do not think these mysteries necessarily need to be solved before we can answer the question [of whether machines can think]."[53] Russell and Norvig agree: "Most AI researchers take the weak AI hypothesis for granted, and don't care about the strong AI hypothesis."[54] There are a few researchers who believe that consciousness is an essential element in intelligence, such as Igor Aleksander, Stan Franklin, Ron Sun, and Pentti Haikonen, although their definition of "consciousness" strays very close to "intelligence". (See artificial consciousness.) Before we can answer this question, we must be clear what we mean by "minds", "mental states" and "consciousness". Consciousness, minds, mental states, meaning[edit] The words "mind" and "consciousness" are used by different communities in different ways. Some new age thinkers, for example, use the word "consciousness" to describe something similar to Bergson's "élan vital": an invisible, energetic fluid that permeates life and especially the mind. Science fiction writers use the word to describe some essential property that makes us human: a machine or alien that is "conscious" will be presented as a fully human character, with intelligence, desires, will, insight, pride and so on. (Science fiction writers also use the words "sentience", "sapience", "self-awareness" or "ghost"—as in the Ghost in the Shell manga and anime series—to describe this essential human property). For others[who?], the words "mind" or "consciousness" are used as a kind of secular synonym for the soul. For philosophers, neuroscientists and cognitive scientists, the words are used in a way that is both more precise and more mundane: they refer to the familiar, everyday experience of having a "thought in your head", like a perception, a dream, an intention or a plan, and to the way we see something, know something, mean something or understand something.[55] "It's not hard to give a commonsense definition of consciousness" observes philosopher John Searle.[56] What is mysterious and fascinating is not so much what it is but how it is: how does a lump of fatty tissue and electricity give rise to this (familiar) experience of perceiving, meaning or thinking? Philosophers call this the hard problem of consciousness. It is the latest version of a classic problem in the philosophy of mind called the "mind-body problem".[57] A related problem is the problem of meaning or understanding (which philosophers call "intentionality"): what is the connection between our thoughts and what we are thinking about (i.e. objects and situations out in the world)? A third issue is the problem of experience (or "phenomenology"): If two people see the same thing, do they have the same experience? Or are there things "inside their head" (called "qualia") that can be different from person to person?[58] Neurobiologists believe all these problems will be solved as we begin to identify the neural correlates of consciousness: the actual relationship between the machinery in our heads and its collective properties; such as the mind, experience and understanding. Some of the harshest critics of artificial intelligence agree that the brain is just a machine, and that consciousness and intelligence are the result of physical processes in the brain.[59] The difficult philosophical question is this: can a computer program, running on a digital machine that shuffles the binary digits of zero and one, duplicate the ability of the neurons to create minds, with mental states (like understanding or perceiving), and ultimately, the experience of consciousness? Arguments that a computer cannot have a mind and mental states[edit] Searle's Chinese room[edit] Main article: Chinese room John Searle asks us to consider a thought experiment: suppose we have written a computer program that passes the Turing test and demonstrates general intelligent action. Suppose, specifically that the program can converse in fluent Chinese. Write the program on 3x5 cards and give them to an ordinary person who does not speak Chinese. Lock the person into a room and have him follow the instructions on the cards. He will copy out Chinese characters and pass them in and out of the room through a slot. From the outside, it will appear that the Chinese room contains a fully intelligent person who speaks Chinese. The question is this: is there anyone (or anything) in the room that understands Chinese? That is, is there anything that has the mental state of understanding, or which has conscious awareness of what is being discussed in Chinese? The man is clearly not aware. The room cannot be aware. The cards certainly are not aware. Searle concludes that the Chinese room, or any other physical symbol system, cannot have a mind.[60] Searle goes on to argue that actual mental states and consciousness require (yet to be described) "actual physical-chemical properties of actual human brains."[61] He argues there are special "causal properties" of brains and neurons that gives rise to minds: in his words "brains cause minds."[62] Related arguments: Leibniz' mill, Davis's telephone exchange, Block's Chinese nation and Blockhead[edit] Gottfried Leibniz made essentially the same argument as Searle in 1714, using the thought experiment of expanding the brain until it was the size of a mill.[63] In 1974, Lawrence Davis imagined duplicating the brain using telephone lines and offices staffed by people, and in 1978 Ned Block envisioned the entire population of China involved in such a brain simulation. This thought experiment is called "the Chinese Nation" or "the Chinese Gym".[64] Ned Block also proposed his Blockhead argument, which is a version of the Chinese room in which the program has been re-factored into a simple set of rules of the form "see this, do that", removing all mystery from the program. Responses to the Chinese room[edit] Responses to the Chinese room emphasize several different points. The systems reply and the virtual mind reply:[65] This reply argues that the system, including the man, the program, the room, and the cards, is what understands Chinese. Searle claims that the man in the room is the only thing which could possibly "have a mind" or "understand", but others disagree, arguing that it is possible for there to be two minds in the same physical place, similar to the way a computer can simultaneously "be" two machines at once: one physical (like a Macintosh) and one "virtual" (like a word processor). Speed, power and complexity replies:[66] Several critics point out that the man in the room would probably take millions of years to respond to a simple question, and would require "filing cabinets" of astronomical proportions. This brings the clarity of Searle's intuition into doubt. Robot reply:[67] To truly understand, some believe the Chinese Room needs eyes and hands. Hans Moravec writes: "If we could graft a robot to a reasoning program, we wouldn't need a person to provide the meaning anymore: it would come from the physical world."[68] Brain simulator reply:[69] What if the program simulates the sequence of nerve firings at the synapses of an actual brain of an actual Chinese speaker? The man in the room would be simulating an actual brain. This is a variation on the "systems reply" that appears more plausible because "the system" now clearly operates like a human brain, which strengthens the intuition that there is something besides the man in the room that could understand Chinese. Other minds reply and the epiphenomena reply:[70] Several people have noted that Searle's argument is just a version of the problem of other minds, applied to machines. Since it is difficult to decide if people are "actually" thinking, we should not be surprised that it is difficult to answer the same question about machines. A related question is whether "consciousness" (as Searle understands it) exists. Searle argues that the experience of consciousness cannot be detected by examining the behavior of a machine, a human being or any other animal. Daniel Dennett points out that natural selection cannot preserve a feature of an animal that has no effect on the behavior of the animal, and thus consciousness (as Searle understands it) cannot be produced by natural selection. Therefore, either natural selection did not produce consciousness, or "strong AI" is correct in that consciousness can be detected by suitably designed Turing test. Is thinking a kind of computation?[edit] Main article: Computational theory of mind The computational theory of mind or "computationalism" claims that the relationship between mind and brain is similar (if not identical) to the relationship between a running program (software) and a computer (hardware). The idea has philosophical roots in Hobbes (who claimed reasoning was "nothing more than reckoning"), Leibniz (who attempted to create a logical calculus of all human ideas), Hume (who thought perception could be reduced to "atomic impressions") and even Kant (who analyzed all experience as controlled by formal rules).[71] The latest version is associated with philosophers Hilary Putnam and Jerry Fodor.[72] This question bears on our earlier questions: if the human brain is a kind of computer then computers can be both intelligent and conscious, answering both the practical and philosophical questions of AI. In terms of the practical question of AI ("Can a machine display general intelligence?"), some versions of computationalism make the claim that (as Hobbes wrote): Reasoning is nothing but reckoning.[10] In other words, our intelligence derives from a form of calculation, similar to arithmetic. This is the physical symbol system hypothesis discussed above, and it implies that artificial intelligence is possible. In terms of the philosophical question of AI ("Can a machine have mind, mental states and consciousness?"), most versions of computationalism claim that (as Stevan Harnad characterizes it): Mental states are just implementations of (the right) computer programs.[73] This is John Searle's "strong AI" discussed above, and it is the real target of the Chinese room argument (according to Harnad).[73] Other related questions[edit] Can a machine have emotions?[edit] If "emotions" are defined only in terms of their effect on behavior or on how they function inside an organism, then emotions can be viewed as a mechanism that an intelligent agent uses to maximize the utility of its actions. Given this definition of emotion, Hans Moravec believes that "robots in general will be quite emotional about being nice people".[74] Fear is a source of urgency. Empathy is a necessary component of good human computer interaction. He says robots "will try to please you in an apparently selfless manner because it will get a thrill out of this positive reinforcement. You can interpret this as a kind of love."[74] Daniel Crevier writes "Moravec's point is that emotions are just devices for channeling behavior in a direction beneficial to the survival of one's species."[75] Can a machine be self-aware?[edit] "Self-awareness", as noted above, is sometimes used by science fiction writers as a name for the essential human property that makes a character fully human. Turing strips away all other properties of human beings and reduces the question to "can a machine be the subject of its own thought?" Can it think about itself? Viewed in this way, a program can be written that can report on its own internal states, such as a debugger.[76] Can a machine be original or creative?[edit] Turing reduces this to the question of whether a machine can "take us by surprise" and argues that this is obviously true, as any programmer can attest.[77] He notes that, with enough storage capacity, a computer can behave in an astronomical number of different ways.[78] It must be possible, even trivial, for a computer that can represent ideas to combine them in new ways. (Douglas Lenat's Automated Mathematician, as one example, combined ideas to discover new mathematical truths.) Kaplan and Haenlein suggest that machines can display scientific creativity, while it seems likely that humans will have the upper hand where artistic creativity is concerned.[79] In 2009, scientists at Aberystwyth University in Wales and the U.K's University of Cambridge designed a robot called Adam that they believe to be the first machine to independently come up with new scientific findings.[80] Also in 2009, researchers at Cornell developed Eureqa, a computer program that extrapolates formulas to fit the data inputted, such as finding the laws of motion from a pendulum's motion. Can a machine be benevolent or hostile?[edit] Main article: Ethics of artificial intelligence This question (like many others in the philosophy of artificial intelligence) can be presented in two forms. "Hostility" can be defined in terms function or behavior, in which case "hostile" becomes synonymous with "dangerous". Or it can be defined in terms of intent: can a machine "deliberately" set out to do harm? The latter is the question "can a machine have conscious states?" (such as intentions) in another form.[53] The question of whether highly intelligent and completely autonomous machines would be dangerous has been examined in detail by futurists (such as the Machine Intelligence Research Institute). The obvious element of drama has also made the subject popular in science fiction, which has considered many differently possible scenarios where intelligent machines pose a threat to mankind; see Artificial intelligence in fiction. One issue is that machines may acquire the autonomy and intelligence required to be dangerous very quickly. Vernor Vinge has suggested that over just a few years, computers will suddenly become thousands or millions of times more intelligent than humans. He calls this "the Singularity".[81] He suggests that it may be somewhat or possibly very dangerous for humans.[82] This is discussed by a philosophy called Singularitarianism. In 2009, academics and technical experts attended a conference to discuss the potential impact of robots and computers and the impact of the hypothetical possibility that they could become self-sufficient and able to make their own decisions. They discussed the possibility and the extent to which computers and robots might be able to acquire any level of autonomy, and to what degree they could use such abilities to possibly pose any threat or hazard. They noted that some machines have acquired various forms of semi-autonomy, including being able to find power sources on their own and being able to independently choose targets to attack with weapons. They also noted that some computer viruses can evade elimination and have achieved "cockroach intelligence". They noted that self-awareness as depicted in science-fiction is probably unlikely, but that there were other potential hazards and pitfalls.[81] Some experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomous functions.[83] The US Navy has funded a report which indicates that as military robots become more complex, there should be greater attention to implications of their ability to make autonomous decisions.[84][85] The President of the Association for the Advancement of Artificial Intelligence has commissioned a study to look at this issue.[86] They point to programs like the Language Acquisition Device which can emulate human interaction. Some have suggested a need to build "Friendly AI", a term coined by Eliezer Yudkowsky, meaning that the advances which are already occurring with AI should also include an effort to make AI intrinsically friendly and humane.[87] Can a machine imitate all human characteristics?[edit] Turing said "It is customary ... to offer a grain of comfort, in the form of a statement that some peculiarly human characteristic could never be imitated by a machine. ... I cannot offer any such comfort, for I believe that no such bounds can be set."[88] Turing noted that there are many arguments of the form "a machine will never do X", where X can be many things, such as: Be kind, resourceful, beautiful, friendly, have initiative, have a sense of humor, tell right from wrong, make mistakes, fall in love, enjoy strawberries and cream, make someone fall in love with it, learn from experience, use words properly, be the subject of its own thought, have as much diversity of behaviour as a man, do something really new.[76] Turing argues that these objections are often based on naive assumptions about the versatility of machines or are "disguised forms of the argument from consciousness". Writing a program that exhibits one of these behaviors "will not make much of an impression."[76] All of these arguments are tangential to the basic premise of AI, unless it can be shown that one of these traits is essential for general intelligence. Can a machine have a soul?[edit] Finally, those who believe in the existence of a soul may argue that "Thinking is a function of man's immortal soul." Alan Turing called this "the theological objection". He writes: In attempting to construct such machines we should not be irreverently usurping His power of creating souls, any more than we are in the procreation of children: rather we are, in either case, instruments of His will providing mansions for the souls that He creates.[89]The discussion on the topic has been reignited as a result of recent claims made by Google's LaMDA artificial intelligence system that it is sentient and had a "soul".[90] LaMDA (Language Model for Dialogue Applications) is an artificial intelligence system that creates chatbots—AI robots designed to communicate with humans—by gathering vast amounts of text from the internet and using algorithms to respond to queries in the most fluid and natural way possible. The transcripts of conversations between scientists and LaMDA reveal that the AI system excels at this, providing answers to challenging topics about the nature of emotions, generating Aesop-style fables on the moment, and even describing its alleged fears.[91] Pretty much all philosophers doubt LaMDA's sentience.[92] Views on the role of philosophy[edit] Some scholars argue that the AI community's dismissal of philosophy is detrimental. In the Stanford Encyclopedia of Philosophy, some philosophers argue that the role of philosophy in AI is underappreciated.[4] Physicist David Deutsch argues that without an understanding of philosophy or its concepts, AI development would suffer from a lack of progress.[93] Conferences and literature[edit] The main conference series on the issue is "Philosophy and Theory of AI" (PT-AI), run by Vincent C. Müller. The main bibliography on the subject, with several sub-sections, is on PhilPapers. A recent survey for Philosophy of AI is Müller (2023).[3] See also[edit] Philosophy portalPsychology portalScience portal AI takeover Artificial brain Artificial consciousness Artificial intelligence Artificial neural network Chatbot Computational theory of mind Computing Machinery and Intelligence Existential risk from artificial general intelligence Functionalism Hubert Dreyfus's views on artificial intelligence Multi-agent system Philosophy of computer science Philosophy of information Philosophy of mind Physical symbol system Simulated reality Superintelligence: Paths, Dangers, Strategies Synthetic intelligence Wireheading Notes[edit] ^ Hubert Dreyfus writes: "In general, by accepting the fundamental assumptions that the nervous system is part of the physical world and that all physical processes can be described in a mathematical formalism which can, in turn, be manipulated by a digital computer, one can arrive at the strong claim that the behavior which results from human 'information processing,' whether directly formalizable or not, can always be indirectly reproduced on a digital machine." [28]. John Searle writes: "Could a man made machine think? Assuming it possible produce artificially a machine with a nervous system, ... the answer to the question seems to be obviously, yes ... Could a digital computer think? If by 'digital computer' you mean anything at all that has a level of description where it can be correctly described as the instantiation of a computer program, then again the answer is, of course, yes, since we are the instantiations of any number of computer programs, and we can think."[29] References[edit] ^ "Philosophy of Computer Science". obo. ^ McCarthy, John. "The Philosophy of AI and the AI of Philosophy". jmc.stanford.edu. Archived from the original on 2018-10-23. Retrieved 2018-09-18. ^ a b Müller, Vincent C. (2023-07-24). "Philosophy of AI: A structured overview". Nathalie A. Smuha (Ed.), Cambridge Handbook on the Law, Ethics and Policy of Artificial Intelligence. ^ a b Bringsjord, Selmer; Govindarajulu, Naveen Sundar (2018), "Artificial Intelligence", in Zalta, Edward N. (ed.), The Stanford Encyclopedia of Philosophy (Fall 2018 ed.), Metaphysics Research Lab, Stanford University, archived from the original on 2019-11-09, retrieved 2018-09-18 ^ Russell & Norvig 2003, p. 947 define the philosophy of AI as consisting of the first two questions, and the additional question of the ethics of artificial intelligence. Fearn 2007, p. 55 writes "In the current literature, philosophy has two chief roles: to determine whether or not such machines would be conscious, and, second, to predict whether or not such machines are possible." The last question bears on the first two. ^ a b This is a paraphrase of the essential point of the Turing test. Turing 1950, Haugeland 1985, pp. 6–9, Crevier 1993, p. 24, Russell & Norvig 2003, pp. 2–3 and 948 ^ a b McCarthy et al. 1955. This assertion was printed in the program for the Dartmouth Conference of 1956, widely considered the "birth of AI."also Crevier 1993, p. 28 ^ a b Newell & Simon 1976 harvnb error: no target: CITEREFNewellSimon1976 (help) and Russell & Norvig 2003, p. 18 ^ a b c d This version is from Searle (1999), and is also quoted in Dennett 1991, p. 435. Searle's original formulation was "The appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to understand and have other cognitive states." (Searle 1980, p. 1). Strong AI is defined similarly by Russell & Norvig (2003, p. 947): "The assertion that machines could possibly act intelligently (or, perhaps better, act as if they were intelligent) is called the 'weak AI' hypothesis by philosophers, and the assertion that machines that do so are actually thinking (as opposed to simulating thinking) is called the 'strong AI' hypothesis." ^ a b Hobbes 1651, chpt. 5 harvnb error: no target: CITEREFHobbes1651 (help) ^ See Russell & Norvig 2003, p. 3, where they make the distinction between acting rationally and being rational, and define AI as the study of the former. ^ Turing, Alan M. (1950). "Computing Machinery and Intelligence". Mind. 49 (236): 433–460. doi:10.1093/mind/LIX.236.433. Archived from the original on 2021-12-22. Retrieved 2020-10-18 – via cogprints. ^ Heder, Mihaly; Paksi, Daniel (2012). "Autonomous Robots and Tacit Knowledge". Appraisal. 9 (2): 8–14 – via academia.edu. ^ Saygin 2000. sfn error: no target: CITEREFSaygin2000 (help) ^ Turing 1950 and see Russell & Norvig 2003, p. 948, where they call his paper "famous" and write "Turing examined a wide variety of possible objections to the possibility of intelligent machines, including virtually all of those that have been raised in the half century since his paper appeared." ^ Turing 1950 under "The Argument from Consciousness" ^ Russell & Norvig 2003, p. 3 ^ McCarthy 1999. ^ Russell & Norvig 2003, pp. 4–5, 32, 35, 36 and 56 ^ Russell and Norvig would prefer the word "rational" to "intelligent". ^ "Artificial Stupidity". The Economist. Vol. 324, no. 7770. 1 August 1992. p. 14. ^ Russell & Norvig (2003, pp. 48–52) consider a thermostat a simple form of intelligent agent, known as a reflex agent. For an in-depth treatment of the role of the thermostat in philosophy see Chalmers (1996, pp. 293–301) "4. Is Experience Ubiquitous?" subsections What is it like to be a thermostat?, Whither panpsychism?, and Constraining the double-aspect principle. ^ Dreyfus 1972, p. 106. ^ Pitts & McCullough 1943. sfn error: no target: CITEREFPittsMcCullough1943 (help) ^ Moravec 1988. ^ Kurzweil 2005, p. 262. Also see Russell & Norvig, p. 957 harvnb error: no target: CITEREFRussellNorvig (help) and Crevier 1993, pp. 271 and 279. The most extreme form of this argument (the brain replacement scenario) was put forward by Clark Glymour in the mid-1970s and was touched on by Zenon Pylyshyn and John Searle in 1980 ^ Eugene Izhikevich (2005-10-27). "Eugene M. Izhikevich, Large-Scale Simulation of the Human Brain". Vesicle.nsi.edu. Archived from the original on 2009-05-01. Retrieved 2010-07-29. ^ Dreyfus 1972, pp. 194–5. ^ Searle 1980, p. 11. ^ Searle 1980, p. 7. ^ Yudkowsky 2008. sfn error: no target: CITEREFYudkowsky2008 (help) ^ Searle writes "I like the straight forwardness of the claim." Searle 1980, p. 4 ^ Dreyfus 1979, p. 156 ^ Gödel, Kurt, 1951, Some basic theorems on the foundations of mathematics and their implications in Solomon Feferman, ed., 1995. Collected works / Kurt Gödel, Vol. III. Oxford University Press: 304-23. - In this lecture, Gödel uses the incompleteness theorem to arrive at the following disjunction: (a) the human mind is not a consistent finite machine, or (b) there exist Diophantine equations for which it cannot decide whether solutions exist. Gödel finds (b) implausible, and thus seems to have believed the human mind was not equivalent to a finite machine, i.e., its power exceeded that of any finite machine. He recognized that this was only a conjecture, since one could never disprove (b). Yet he considered the disjunctive conclusion to be a "certain fact". ^ Lucas 1961, Russell & Norvig 2003, pp. 949–950, Hofstadter 1979, pp. 471–473, 476–477 ^ Graham Oppy (20 January 2015). "Gödel's Incompleteness Theorems". Stanford Encyclopedia of Philosophy. Archived from the original on 3 May 2021. Retrieved 27 April 2016. These Gödelian anti-mechanist arguments are, however, problematic, and there is wide consensus that they fail. ^ Stuart J. Russell; Peter Norvig (2010). "26.1.2: Philosophical Foundations/Weak AI: Can Machines Act Intelligently?/The mathematical objection". Artificial Intelligence: A Modern Approach (3rd ed.). Upper Saddle River, NJ: Prentice Hall. ISBN 978-0-13-604259-4. ...even if we grant that computers have limitations on what they can prove, there is no evidence that humans are immune from those limitations. ^ Mark Colyvan. An Introduction to the Philosophy of Mathematics. Cambridge University Press, 2012. From 2.2.2, 'Philosophical significance of Gödel's incompleteness results': "The accepted wisdom (with which I concur) is that the Lucas-Penrose arguments fail." ^ LaForte, G., Hayes, P. J., Ford, K. M. 1998. Why Gödel's theorem cannot refute computationalism. Artificial Intelligence, 104:265-286, 1998. ^ Russell & Norvig 2003, p. 950 They point out that real machines with finite memory can be modeled using propositional logic, which is formally decidable, and Gödel's argument does not apply to them at all. ^ Hofstadter 1979 ^ According to Hofstadter 1979, pp. 476–477, this statement was first proposed by C. H. Whiteley ^ Hofstadter 1979, pp. 476–477, Russell & Norvig 2003, p. 950, Turing 1950 under "The Argument from Mathematics" where he writes "although it is established that there are limitations to the powers of any particular machine, it has only been stated, without sort of proof, that no such limitations apply to the human intellect." ^ Penrose 1989 ^ Litt, Abninder; Eliasmith, Chris; Kroon, Frederick W.; Weinstein, Steven; Thagard, Paul (6 May 2006). "Is the Brain a Quantum Computer?". Cognitive Science. 30 (3): 593–603. doi:10.1207/s15516709cog0000_59. PMID 21702826. ^ Dreyfus 1972, Dreyfus 1979, Dreyfus & Dreyfus 1986. See also Russell & Norvig 2003, pp. 950–952, Crevier 1993, pp. 120–132 and Fearn 2007, pp. 50–51 ^ Russell & Norvig 2003, pp. 950–51 ^ Turing 1950 under "(8) The Argument from the Informality of Behavior" ^ a b Russell & Norvig 2003, p. 52 ^ See Brooks 1990 and Moravec 1988 ^ Daniel Kahneman (2011). Thinking, Fast and Slow. Macmillan. ISBN 978-1-4299-6935-2. Archived from the original on March 15, 2023. Retrieved April 8, 2012. ^ Crevier 1993, p. 125 ^ a b Turing 1950 under "(4) The Argument from Consciousness". See also Russell & Norvig 2003, pp. 952–3, where they identify Searle's argument with Turing's "Argument from Consciousness." ^ Russell & Norvig 2003, p. 947 ^ Blackmore 2005, p. 1. ^ "[P]eople always tell me it was very hard to define consciousness, but I think if you're just looking for the kind of commonsense definition that you get at the beginning of the investigation, and not at the hard nosed scientific definition that comes at the end, it's not hard to give commonsense definition of consciousness." The Philosopher's Zone: The question of consciousness Archived 2007-11-28 at the Wayback Machine. Also see Dennett 1991 ^ Blackmore 2005, p. 2 ^ Russell & Norvig 2003, pp. 954–956 ^ For example, John Searle writes: "Can a machine think? The answer is, obvious, yes. We are precisely such machines." (Searle 1980, p. 11) ^ Searle 1980. See also Cole 2004, Russell & Norvig 2003, pp. 958–960, Crevier 1993, pp. 269–272 and Hearn 2007, pp. 43–50 harvnb error: no target: CITEREFHearn2007 (help) ^ Searle 1980, p. 13 ^ Searle 1984 harvnb error: no target: CITEREFSearle1984 (help) ^ Cole 2004, 2.1, Leibniz 1714, 17 harvnb error: no target: CITEREFLeibniz1714 (help) ^ Cole 2004, 2.3 ^ Searle 1980 under "1. The Systems Reply (Berkeley)", Crevier 1993, p. 269, Russell & Norvig 2003, p. 959, Cole 2004, 4.1. Among those who hold to the "system" position (according to Cole) are Ned Block, Jack Copeland, Daniel Dennett, Jerry Fodor, John Haugeland, Ray Kurzweil and Georges Rey. Those who have defended the "virtual mind" reply include Marvin Minsky, Alan Perlis, David Chalmers, Ned Block and J. Cole (again, according to Cole 2004) ^ Cole 2004, 4.2 ascribes this position to Ned Block, Daniel Dennett, Tim Maudlin, David Chalmers, Steven Pinker, Patricia Churchland and others. ^ Searle 1980 under "2. The Robot Reply (Yale)". Cole 2004, 4.3 ascribes this position to Margaret Boden, Tim Crane, Daniel Dennett, Jerry Fodor, Stevan Harnad, Hans Moravec and Georges Rey ^ Quoted in Crevier 1993, p. 272 ^ Searle 1980 under "3. The Brain Simulator Reply (Berkeley and M.I.T.)" Cole 2004 ascribes this position to Paul and Patricia Churchland and Ray Kurzweil ^ Searle 1980 under "5. The Other Minds Reply", Cole 2004, 4.4. Turing 1950 makes this reply under "(4) The Argument from Consciousness." Cole ascribes this position to Daniel Dennett and Hans Moravec. ^ Dreyfus 1979, p. 156, Haugeland 1985, pp. 15–44 ^ Horst 2005 harvnb error: no target: CITEREFHorst2005 (help) ^ a b Harnad 2001 ^ a b Quoted in Crevier 1993, p. 266 ^ Crevier 1993, p. 266 ^ a b c Turing 1950 under "(5) Arguments from Various Disabilities" ^ Turing 1950 under "(6) Lady Lovelace's Objection" ^ Turing 1950 under "(5) Argument from Various Disabilities" ^ "Kaplan Andreas; Michael Haenlein". Business Horizons. 62 (1): 15–25. January 2019. doi:10.1016/j.bushor.2018.08.004. S2CID 158433736. ^ Katz, Leslie (2009-04-02). "Robo-scientist makes gene discovery-on its own | Crave - CNET". News.cnet.com. Archived from the original on July 12, 2012. Retrieved 2010-07-29. ^ a b Scientists Worry Machines May Outsmart Man Archived 2017-07-01 at the Wayback Machine By JOHN MARKOFF, NY Times, July 26, 2009. ^ The Coming Technological Singularity: How to Survive in the Post-Human Era, by Vernor Vinge, Department of Mathematical Sciences, San Diego State University, (c) 1993 by Vernor Vinge. ^ Call for debate on killer robots Archived 2009-08-07 at the Wayback Machine, By Jason Palmer, Science and technology reporter, BBC News, 8/3/09. ^ Science New Navy-funded Report Warns of War Robots Going "Terminator" Archived 2009-07-28 at the Wayback Machine, by Jason Mick (Blog), dailytech.com, February 17, 2009. ^ Navy report warns of robot uprising, suggests a strong moral compass Archived 2011-06-04 at the Wayback Machine, by Joseph L. Flatley engadget.com, Feb 18th 2009. ^ AAAI Presidential Panel on Long-Term AI Futures 2008-2009 Study Archived 2009-08-28 at the Wayback Machine, Association for the Advancement of Artificial Intelligence, Accessed 7/26/09. ^ Article at Asimovlaws.com, July 2004, accessed 7/27/09. Archived June 30, 2009, at the Wayback Machine ^ 'Can digital computers think?'. Talk broadcast on BBC Third Programme, 15 May 1951. http://www.turingarchive.org/viewer/?id=459&title=8 ^ Turing 1950 under "(1) The Theological Objection", although he also writes, "I am not very impressed with theological arguments whatever they may be used to support" ^ Brandon Specktor published (2022-06-13). "Google AI 'is sentient,' software engineer claims before being suspended". livescience.com. Archived from the original on 2022-06-14. Retrieved 2022-06-14. ^ Lemoine, Blake (2022-06-11). "Is LaMDA Sentient? — an Interview". Medium. Archived from the original on 2022-06-13. Retrieved 2022-06-14. ^ M.Morioka et al. (2023-01-15) Artificial Intelligence, Robots, and Philosophy Archived 2022-12-28 at the Wayback Machine, pp.2-4. ^ Deutsch, David (2012-10-03). "Philosophy will be the key that unlocks artificial intelligence | David Deutsch". the Guardian. Archived from the original on 2013-09-27. Retrieved 2018-09-18. Works cited[edit] Adam, Alison (1989). Artificial Knowing: Gender and the Thinking Machine. Routledge & CRC Press. ISBN 978-0-415-12963-3 Benjamin, Ruha (2019). Race After Technology: Abolitionist Tools for the New Jim Code. Wiley. ISBN 978-1-509-52643-7 Blackmore, Susan (2005), Consciousness: A Very Short Introduction, Oxford University Press Bostrom, Nick (2014), Superintelligence: Paths, Dangers, Strategies, Oxford University Press, ISBN 978-0-19-967811-2 Brooks, Rodney (1990), "Elephants Don't Play Chess" (PDF), Robotics and Autonomous Systems, 6 (1–2): 3–15, CiteSeerX 10.1.1.588.7539, doi:10.1016/S0921-8890(05)80025-9, retrieved 2007-08-30 Bryson, Joanna (2019). The Artificial Intelligence of the Ethics of Artificial Intelligence: An Introductory Overview for Law and Regulation, 34. Chalmers, David J (1996), The Conscious Mind: In Search of a Fundamental Theory, Oxford University Press, New York, ISBN 978-0-19-511789-9 Cole, David (Fall 2004), "The Chinese Room Argument", in Zalta, Edward N. (ed.), The Stanford Encyclopedia of Philosophy. Crawford, Kate (2021). Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence. Yale University Press. Crevier, Daniel (1993). AI: The Tumultuous Search for Artificial Intelligence. New York, NY: BasicBooks. ISBN 0-465-02997-3. Dennett, Daniel (1991), Consciousness Explained, The Penguin Press, ISBN 978-0-7139-9037-9 Dreyfus, Hubert (1972), What Computers Can't Do, New York: MIT Press, ISBN 978-0-06-011082-6 Dreyfus, Hubert (1979), What Computers Still Can't Do, New York: MIT Press. Dreyfus, Hubert; Dreyfus, Stuart (1986), Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer, Oxford, UK: Blackwell Fearn, Nicholas (2007), The Latest Answers to the Oldest Questions: A Philosophical Adventure with the World's Greatest Thinkers, New York: Grove Press Gladwell, Malcolm (2005), Blink: The Power of Thinking Without Thinking, Boston: Little, Brown, ISBN 978-0-316-17232-5. Harnad, Stevan (2001), "What's Wrong and Right About Searle's Chinese Room Argument?", in Bishop, M.; Preston, J. (eds.), Essays on Searle's Chinese Room Argument, Oxford University Press Haraway, Donna (1985). A Cyborg Manifesto. Haugeland, John (1985), Artificial Intelligence: The Very Idea, Cambridge, Mass.: MIT Press. Hofstadter, Douglas (1979), Gödel, Escher, Bach: an Eternal Golden Braid. Horst, Steven (2009), "The Computational Theory of Mind", in Zalta, Edward N. (ed.), The Stanford Encyclopedia of Philosophy, Metaphysics Research Lab, Stanford University. Kaplan, Andreas; Haenlein, Michael (2018), "Siri, Siri in my Hand, who's the Fairest in the Land? On the Interpretations, Illustrations and Implications of Artificial Intelligence", Business Horizons, 62: 15–25, doi:10.1016/j.bushor.2018.08.004, S2CID 158433736 Kurzweil, Ray (2005), The Singularity is Near, New York: Viking Press, ISBN 978-0-670-03384-3. Lucas, John (1961), "Minds, Machines and Gödel", in Anderson, A.R. (ed.), Minds and Machines. Malabou, Catherine (2019). Morphing Intelligence: From IQ Measurement to Artificial Brains. (C. Shread, Trans.). Columbia University Press. McCarthy, John; Minsky, Marvin; Rochester, Nathan; Shannon, Claude (1955), A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence, archived from the original on 2008-09-30. McCarthy, John (1999), What is AI?, archived from the original on 4 December 2022, retrieved 4 December 2022 McDermott, Drew (May 14, 1997), "How Intelligent is Deep Blue", New York Times, archived from the original on October 4, 2007, retrieved October 10, 2007 Moravec, Hans (1988), Mind Children, Harvard University Press Penrose, Roger (1989), The Emperor's New Mind: Concerning Computers, Minds, and The Laws of Physics, Oxford University Press, ISBN 978-0-14-014534-2c Rescorla, Michael, "The Computational Theory of Mind", in:Edward N. Zalta (ed.), The Stanford Encyclopedia of Philosophy (Fall 2020 Edition) Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2 Searle, John (1980), "Minds, Brains and Programs" (PDF), Behavioral and Brain Sciences, 3 (3): 417–457, doi:10.1017/S0140525X00005756, S2CID 55303721, archived from the original (PDF) on 2015-09-23 Searle, John (1992), The Rediscovery of the Mind, Cambridge, Massachusetts: M.I.T. Press Searle, John (1999), Mind, language and society, New York, NY: Basic Books, ISBN 978-0-465-04521-1, OCLC 231867665 Turing, Alan (October 1950), "Computing Machinery and Intelligence", Mind, LIX (236): 433–460, doi:10.1093/mind/LIX.236.433, ISSN 0026-4423 vtePhilosophy of mindPhilosophers Anscombe Austin Aquinas Bain Bergson Block Brentano Broad Burge Chalmers Churchland Dennett Dharmakirti Davidson Descartes Goldman Heidegger Husserl Feyerabend Fodor James Kierkegaard Leibniz Lewis McDowell Merleau-Ponty Minsky Moore Nagel Parfit Putnam Popper Rorty Ryle Searle Spinoza Turing Vasubandhu Wittgenstein Zhuangzi more... Theories Behaviorism Biological naturalism Dualism Eliminative materialism Emergent materialism Epiphenomenalism Functionalism Idealism Interactionism Materialism Monism Naïve realism Neurophenomenology Neutral monism New mysterianism Nondualism Occasionalism Parallelism Phenomenalism Phenomenology Physicalism Type physicalism Property dualism Representational Solipsism Substance dualism Concepts Abstract object Artificial intelligence Chinese room Creativity Cognition Cognitive closure Concept Consciousness Hard problem of consciousness Hypostatic abstraction Idea Identity Intelligence Intentionality Introspection Intuition Language of thought Mental event Mental image Mental process Mental property Mental representation Mind Mind–body problem Pain Problem of other minds Propositional attitude Qualia Tabula rasa Understanding Zombie Related Metaphysics Philosophy of artificial intelligence / information / perception / self Category Philosophers category Project Task Force vtePhilosophy of scienceConcepts Analysis Analytic–synthetic distinction A priori and a posteriori Causality Commensurability Consilience Construct Creative synthesis Demarcation problem Empirical evidence Explanatory power Fact Falsifiability Feminist method Functional contextualism Ignoramus et ignorabimus Inductive reasoning Intertheoretic reduction Inquiry Nature Objectivity Observation Paradigm Problem of induction Scientific evidence Evidence-based practice Scientific law Scientific method Scientific pluralism Scientific Revolution Scientific theory Testability Theory choice Theory-ladenness Underdetermination Unity of science more... Theories Coherentism Confirmation holism Constructive empiricism Constructive realism Constructivist epistemology Contextualism Conventionalism Deductive-nomological model Epistemological anarchism Evolutionism Fallibilism Foundationalism Hypothetico-deductive model Inductionism Instrumentalism Model-dependent realism Naturalism Physicalism Positivism / Reductionism / Determinism Pragmatism Rationalism / Empiricism Received view / Semantic view of theories Scientific essentialism Scientific formalism Scientific realism / Anti-realism Scientific skepticism Scientism Structuralism Uniformitarianism Vitalism Philosophy of... Biology Chemistry Physics Space and time Social science Archaeology Economics‎ Geography History Linguistics Psychology Related topics Criticism of science Descriptive science Epistemology Faith and rationality Hard and soft science History and philosophy of science Normative science Protoscience Pseudoscience Relationship between religion and science Rhetoric of science Science studies Sociology of scientific ignorance Sociology of scientific knowledge Philosophers of sciencePrecursors Roger Bacon Francis Bacon Galileo Galilei Isaac Newton Auguste Comte Henri Poincaré Pierre Duhem Rudolf Steiner Karl Pearson Charles Sanders Peirce Wilhelm Windelband Alfred North Whitehead Bertrand Russell Otto Neurath C. D. Broad Michael Polanyi Hans Reichenbach Rudolf Carnap Karl Popper Carl Gustav Hempel W. V. O. Quine Thomas Kuhn Imre Lakatos Paul Feyerabend Ian Hacking Bas van Fraassen Larry Laudan Category Philosophy portal Science portal vtePsychology History Philosophy Portal Psychologist Basic psychology Abnormal Affective neuroscience Affective science Behavioral genetics Behavioral neuroscience Behaviorism Cognitive/Cognitivism Cognitive neuroscience Social Comparative Cross-cultural Cultural Developmental Differential Ecological Evolutionary Experimental Gestalt Intelligence Mathematical Moral Neuropsychology Perception Personality Positive Psycholinguistics Psychophysiology Quantitative Social Theoretical Applied psychology Anomalistic Applied behavior analysis Assessment Clinical Coaching Community Consumer Counseling Critical Educational Ergonomics Feminist Forensic Health Industrial and organizational Legal Media Medical Military Music Occupational health Pastoral Political Psychometrics Psychotherapy Religion School Sport and exercise Suicidology Systems Traffic Methodologies Animal testing Archival research Behavior epigenetics Case study Content analysis Experiments Human subject research Interviews Neuroimaging Observation Psychophysics Qualitative research Quantitative research Self-report inventory Statistical surveys Concepts Behavior Behavioral engineering Behavioral genetics Behavioral neuroscience Cognition Competence Consciousness Consumer behavior Emotions Feelings Human factors and ergonomics Intelligence Mind Psychology of religion PsychometricsPsychologists Wilhelm Wundt William James Ivan Pavlov Sigmund Freud Edward Thorndike Carl Jung John B. Watson Clark L. Hull Kurt Lewin Jean Piaget Gordon Allport J. P. Guilford Carl Rogers Erik Erikson B. F. Skinner Donald O. Hebb Ernest Hilgard Harry Harlow Raymond Cattell Abraham Maslow Neal E. Miller Jerome Bruner Donald T. Campbell Hans Eysenck Herbert A. Simon David McClelland Leon Festinger George A. Miller Richard Lazarus Stanley Schachter Robert Zajonc Albert Bandura Roger Brown Endel Tulving Lawrence Kohlberg Noam Chomsky Ulric Neisser Jerome Kagan Walter Mischel Elliot Aronson Daniel Kahneman Paul Ekman Michael Posner Amos Tversky Bruce McEwen Larry Squire Richard E. Nisbett Martin Seligman Ed Diener Shelley E. Taylor John Anderson Ronald C. Kessler Joseph E. LeDoux Richard Davidson Susan Fiske Roy Baumeister Lists Counseling topics Disciplines Organizations Outline Psychologists Psychotherapies Research methods Schools of thought Timeline Topics Wiktionary definition Wiktionary category Wikisource Wikimedia Commons Wikiquote Wikinews Wikibooks vtePhilosophyBranchesBranches Aesthetics Applied philosophy Epistemology Ethics Logic Metaphilosophy Metaphysics Philosophy of language Philosophy of mathematics Philosophy of mind Philosophy of religion Philosophy of science Political philosophy Practical philosophy Social philosophy Theoretical philosophy Aesthetics Aesthetic response Formalism Institutionalism Epistemology Empiricism Fideism Naturalism Particularism Rationalism Skepticism Solipsism Ethics Consequentialism Deontology Virtue Free will Compatibilism Determinism Hard Incompatibilism Hard Libertarianism Metaphysics Atomism Dualism Idealism Monism Naturalism Realism Mind Behaviorism Eliminativism Emergentism Epiphenomenalism Functionalism Objectivism Subjectivism Normativity Absolutism Particularism Relativism Nihilism Skepticism Universalism Ontology Action Event Process Reality Anti-realism Conceptualism Idealism Materialism Naturalism Nominalism Physicalism Realism By eraBy era Ancient Western Medieval Renaissance Early modern Modern Contemporary AncientChinese Agriculturalism Confucianism Legalism Logicians Mohism Chinese naturalism Taoism Yangism Greco-Roman Presocratic Ionians Pythagoreans Eleatics Atomists Sophists Cyrenaics Cynicism Eretrian school Megarian school Academy Peripatetic school Hellenistic philosophy Pyrrhonism Stoicism Epicureanism Academic Skepticism Middle Platonism School of the Sextii Neopythagoreanism Second Sophistic Neoplatonism Church Fathers Indian Hindu Samkhya Nyaya Vaisheshika Yoga Mīmāṃsā Ājīvika Ajñana Cārvāka Jain Anekantavada Syādvāda Buddhist Abhidharma Sarvāstivadā Pudgalavada Sautrāntika Madhyamaka Svatantrika and Prasangika Śūnyatā Yogacara Tibetan Persian Mazdakism Mithraism Zoroastrianism Zurvanism MedievalEast Asian Neotaoism Tiantai Huayan Chan Zen Neo-Confucianism Korean Confucianism European Christian Augustinianism Scholasticism Thomism Scotism Occamism Renaissance humanism Indian Vedanta Acintya bheda abheda Advaita Bhedabheda Dvaita Nimbarka Sampradaya Shuddhadvaita Vishishtadvaita Navya-Nyāya Islamic Aristotelianism Averroism Avicennism Illuminationism ʿIlm al-Kalām Sufi Jewish Judeo-Islamic Modern Anarchism Classical Realism Collectivism Conservatism Determinism Dualism Edo neo-Confucianism Empiricism Existentialism Foundationalism Historicism Holism Humanism Anti- Idealism Absolute British German Objective Subjective Transcendental Individualism Kokugaku Liberalism Materialism Modernism Monism Naturalism Natural law Nihilism New Confucianism Neo-scholasticism Pragmatism Phenomenology Positivism Reductionism Rationalism Social contract Socialism Transcendentalism Utilitarianism People Cartesianism Kantianism Neo Kierkegaardianism Krausism Hegelianism Marxism Newtonianism Nietzscheanism Spinozism ContemporaryAnalytic Applied ethics Analytic feminism Analytical Marxism Communitarianism Consequentialism Critical rationalism Experimental philosophy Falsificationism Foundationalism / Coherentism Internalism and externalism Logical positivism Legal positivism Meta-ethics Moral realism Quinean naturalism Normative ethics Ordinary language philosophy Postanalytic philosophy Quietism Rawlsian Reformed epistemology Systemics Scientism Scientific realism Scientific skepticism Transactionalism Contemporary utilitarianism Vienna Circle Wittgensteinian Continental Critical theory Deconstruction Existentialism Feminist Frankfurt School Hermeneutics Neo-Marxism New Historicism Phenomenology Posthumanism Postmodernism Post-structuralism Social constructionism Structuralism Western Marxism Miscellaneous Kyoto School Objectivism Postcritique Russian cosmism more... By regionBy regionAfrican Bantu Egyptian Ethiopian Africana Eastern Buddhist Chinese Indian Indonesian Japanese Korean Taiwanese Vietnamese Middle Eastern Iranian Islamic Jewish Pakistani Turkish Western American Australian British Scottish Canada Czech Danish Dutch French German Greek Italian Maltese Polish Slovene Spanish Miscellaneous Amerindian Aztec Romanian Russian Yugoslav Philosophy portal Category Authority control databases: National Israel United States Retrieved from "https://en.wikipedia.org/w/index.php?title=Philosophy_of_artificial_intelligence&oldid=1204635119" Categories: Philosophy of artificial intelligencePhilosophy of sciencePhilosophy of technologyPhilosophy of mindOpen problemsHidden categories: Harv and Sfn no-target errorsWebarchive template wayback linksArticles with short descriptionShort description is different from WikidataAll articles with unsourced statementsArticles with unsourced statements from April 2017Wikipedia articles needing clarification from April 2017All articles with specifically marked weasel-worded phrasesArticles with specifically marked weasel-worded phrases from April 2017Articles with excerptsArticles with J9U identifiersArticles with LCCN identifiersArticles containing video clips This page was last edited on 7 February 2024, at 14:26 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License 4.0; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policy About Wikipedia Disclaimers Contact Wikipedia Code of Conduct Developers Statistics Cookie statement Mobile view Toggle limited content width

Titel: Just a moment...

Just a moment...Enable JavaScript and cookies to continue

Titel: AI Trounces Philosophers in Answering Philosophical Questions - The New Stack

AI Trounces Philosophers in Answering Philosophical Questions - The New Stack TNS OK SUBSCRIBE Join our community of software engineering leaders and aspirational developers. Always stay in-the-know by getting the most important news and exclusive content delivered fresh to your inbox to learn more about at-scale software development. EMAIL ADDRESS REQUIRED SUBSCRIBE RESUBSCRIPTION REQUIRED It seems that you've previously unsubscribed from our newsletter in the past. Click the button below to open the re-subscribe form in a new tab. When you're done, simply close that tab and continue with this form to complete your subscription. RE-SUBSCRIBE The New Stack does not sell your information or share it with unaffiliated third parties. By continuing, you agree to our Terms of Use and Privacy Policy. Welcome and thank you for joining The New Stack community! Please answer a few simple questions to help us deliver the news and resources you are interested in. FIRST NAME REQUIRED LAST NAME REQUIRED COMPANY NAME REQUIRED COUNTRY REQUIRED Select ... United States Canada India United Kingdom Germany France --- Afghanistan Albania Algeria American Samoa Andorra Angola Anguilla Antarctica Antigua and Barbuda Argentina Armenia Aruba Asia/Pacific Region Australia Austria Azerbaijan Bahamas Bahrain Bangladesh Barbados Belarus Belgium Belize Benin Bermuda Bhutan Bolivia Bonaire, Sint Eustatius and Saba Bosnia and Herzegovina Botswana Bouvet Island Brazil British Indian Ocean Territory Brunei Darussalam Bulgaria Burkina Faso Burundi Cambodia Cameroon Canada Cape Verde Cayman Islands Central African Republic Chad Chile China Christmas Island Cocos (Keeling) Islands Colombia Comoros Congo Congo, The Democratic Republic of the Cook Islands Costa Rica Croatia Cuba Curaçao Cyprus Czech Republic Côte d'Ivoire Denmark Djibouti Dominica Dominican Republic Ecuador Egypt El Salvador Equatorial Guinea Eritrea Estonia Ethiopia Falkland Islands (Malvinas) Faroe Islands Fiji Finland France French Guiana French Polynesia French Southern Territories Gabon Gambia Georgia Germany Ghana Gibraltar Greece Greenland Grenada Guadeloupe Guam Guatemala Guernsey Guinea Guinea-Bissau Guyana Haiti Heard Island and Mcdonald Islands Holy See (Vatican City State) Honduras Hong Kong Hungary Iceland India Indonesia Iran, Islamic Republic Of Iraq Ireland Isle of Man Israel Italy Jamaica Japan Jersey Jordan Kazakhstan Kenya Kiribati Korea, Republic of Kuwait Kyrgyzstan Laos Latvia Lebanon Lesotho Liberia Libyan Arab Jamahiriya Liechtenstein Lithuania Luxembourg Macao Madagascar Malawi Malaysia Maldives Mali Malta Marshall Islands Martinique Mauritania Mauritius Mayotte Mexico Micronesia, Federated States of Moldova, Republic of Monaco Mongolia Montenegro Montserrat Morocco Mozambique Myanmar Namibia Nauru Nepal Netherlands Netherlands Antilles New Caledonia New Zealand Nicaragua Niger Nigeria Niue Norfolk Island North Korea North Macedonia Northern Mariana Islands Norway Oman Pakistan Palau Palestinian Territory, Occupied Panama Papua New Guinea Paraguay Peru Philippines Pitcairn Islands Poland Portugal Puerto Rico Qatar Reunion Romania Russian Federation Rwanda Saint Barthélemy Saint Helena Saint Kitts and Nevis Saint Lucia Saint Martin Saint Martin Saint Pierre and Miquelon Saint Vincent and the Grenadines Samoa San Marino Sao Tome and Principe Saudi Arabia Senegal Serbia Serbia and Montenegro Seychelles Sierra Leone Singapore Sint Maarten Slovakia Slovenia Solomon Islands Somalia South Africa South Georgia and the South Sandwich Islands South Sudan Spain Sri Lanka Sudan Suriname Svalbard and Jan Mayen Swaziland Sweden Switzerland Syrian Arab Republic Taiwan Tajikistan Tanzania, United Republic of Thailand Timor-Leste Togo Tokelau Tonga Trinidad and Tobago Tunisia Turkey Turkmenistan Turks and Caicos Islands Tuvalu Uganda Ukraine United Arab Emirates United Kingdom United States United States Minor Outlying Islands Uruguay Uzbekistan Vanuatu Venezuela Vietnam Virgin Islands, British Virgin Islands, U.S. Wallis and Futuna Western Sahara Yemen Zambia Zimbabwe Åland Islands ZIPCODE REQUIRED Great to meet you! Tell us a bit about your job so we can cover the topics you find most relevant. What is your job level? REQUIRED Select ... C-Level VP/Director Manager/Supervisor Mid Level or Senior Non-Managerial Staff Entry Level/Junior Staff Freelancer/Contractor Student/Intern Other ... Which of these most closely describes your job role? REQUIRED Select ... Developer/Software Engineer SysAdmin/Operations/SRE Architect Security Professional DevOps Engineer/Team Community Manager/Developer Advocate IT management, including CIO/CISO/CTO Business Development/Marketing/Sales Enthusiast/Hobbyist Other ... How many employees are in the organization you work with? REQUIRED Select ... Self-employed 2-10 11-50 51-250 251-1,000 1,001-10,000 > 10,000 I am not working What option best describes the type of organization you work for? REQUIRED Select ... “End user” organization that primarily uses IT products and services to support their business deliverables Hardware / software vendor or supplier Cloud service provider or managed service provider System integrator or IT consulting firm Other ... Which of the following best describes your organization's primary industry? REQUIRED Select ... Advertising/Marketing Aerospace/Aviation Agriculture Automotive Biotech/Pharmaceutical Business Services (accounting, consulting, etc.) Computers/Information Technology Construction Education Facilities/Service Industry Finance/Financial Services (banking, insurance, etc.) Government Healthcare Human Resources Legal Life sciences (biotech, pharmaceuticals, etc.) Manufacturing Media Non-profit Real Estate Retail/Consumer Goods Telecommunications Transportation/Logistics Travel/Hospitality/Entertainment Utility/Energy Other ... LINKEDIN PROFILE URL REQUIRED Welcome! We’re so glad you’re here. You can expect all the best TNS content to arrive Monday through Friday to keep you on top of the news and at the top of your game. What’s next? Check your inbox for a confirmation email where you can adjust your preferences and even join additional groups. Follow TNS on your favorite social media networks. Become a TNS follower on LinkedIn. Check out the latest featured and trending stories while you wait for your first TNS newsletter. PREV 1 of 2 NEXT VOXPOP WASM as a Personal Project? How often do you use WebAssembly for personal projects, or just to learn the technology? ✓ Very frequently, almost every day 0% ✓ Relatively frequently, a few times a week 0% ✓ Infrequently, a few times a month 0% ✓ Very infrequently, a few times a year 0% ✓ Never 0% Thanks for your opinion! Subscribe below to get the final results, published exclusively in our TNS Update newsletter: SUBMIT Search More Results ARCHITECTURE Cloud Native Ecosystem Containers Edge Computing Microservices Networking Serverless Storage ENGINEERING AI Frontend Development Software Development API Management Python JavaScript TypeScript WebAssembly Cloud Services Data Security OPERATIONS Platform Engineering Operations CI/CD Tech Careers Tech Culture DevOps Kubernetes Observability Service Mesh CHANNELS Podcasts Ebooks Events Newsletter TNS RSS Feeds THE NEW STACK About / Contact Sponsors Sponsorship Contributions PODCASTS EBOOKS EVENTS NEWSLETTER ARCHITECTURE ENGINEERING OPERATIONS Cloud Native Ecosystem Containers Edge Computing Microservices Networking Serverless Storage Cloud Native Companies Are Overspending on CVE Management Mar 13th 2024 6:12am, by John Speed Meyers Finally, Platform Engineering for Enterprise Cloud Migration Mar 13th 2024 3:00am, by Jennifer Riggins Meet DBOS: A Database Alternative to Kubernetes Mar 12th 2024 4:00am, by Joab Jackson Cloud Native Computing and AI: A Q&A with CNCF's Head of Ecosystem Mar 11th 2024 9:48am, by Raghavan "Rags" Srinivas With YAMLScript, YAML Becomes a Proper Programming Language Mar 11th 2024 6:55am, by Joab Jackson Simplify Linux and Docker Command Lines with Bash Completion Mar 9th 2024 6:00am, by Jack Wallen Observability Is a Multicluster App Developer's Best Friend Mar 1st 2024 7:42am, by Asaf Yigal Safer Image Builds with Cloud Native Buildpacks and Wolfi Feb 28th 2024 10:00am, by Ram Iyengar How to Deploy GitLab Server Using Docker and Ubuntu Feb 26th 2024 10:15am, by Jack Wallen How to Address Kubernetes Risks and Vulnerabilities Head-on Feb 26th 2024 6:47am, by Giri Radhakrishnan Architecting for Industrial IoT Workloads: A Blueprint Jan 31st 2024 7:34am, by Dunith Danushka Enabling AI in IoT Apps with a Cloud-to-Edge Database Jan 31st 2024 6:11am, by Mark Gamble Why Distributed Application Environments Need a Consistent Security Posture Jan 29th 2024 9:45am, by Neha Mallik AI Engineering: What Developers Need to Think About in 2024 Jan 2nd 2024 1:30am, by David Eastman For Robust Edge Computing, Plan for the ‘What Ifs’ Dec 18th 2023 12:30pm, by Anton Smith Transforming Identity and Access Management with Event Sourcing Mar 4th 2024 10:00am, by Dakshitha Ratnayake Observability Is a Multicluster App Developer's Best Friend Mar 1st 2024 7:42am, by Asaf Yigal The Power of K8s API Solutions: Revolutionizing Industries Feb 27th 2024 10:25am, by Kay James Kubernetes Predictions Were Wrong Feb 21st 2024 9:00am, by Steve Fenton Composable Architectures vs. Microservices: Which Is Best? Feb 16th 2024 7:28am, by Michel Murabito Simplify Kubernetes Hosted Control Planes with K0smotron Mar 11th 2024 10:00am, by Jussi Nummelin The Black Hole That Is the Kubernetes Network Mar 4th 2024 6:30am, by Mitch Connors Netflix Releases bpftop: An eBPF-Based Application Monitor Feb 27th 2024 8:53am, by Steven J. Vaughan-Nichols Samba Network Shares for RHEL-Based Linux Distributions Feb 25th 2024 6:00am, by Jack Wallen Traefik Proxy v3 Adds WebAssembly and Kubernetes Gateway API Support Feb 15th 2024 4:00am, by Steven J. Vaughan-Nichols Meet DBOS: A Database Alternative to Kubernetes Mar 12th 2024 4:00am, by Joab Jackson Pulumi Templates for GenAI Stacks: Pinecone, LangChain First Feb 21st 2024 9:00am, by Joab Jackson CNCF CloudEvents: A Li'l Message Envelope That Travels Far Jan 31st 2024 4:00am, by Joab Jackson Bringing the AWS Serverless Strategy to Azure Jan 19th 2024 6:00am, by Rak Siva Serverless Computing In 2024: GenAI Influence, Security, 5G Jan 4th 2024 5:00am, by Chris J. Preimesberger Why Databases Should Bypass the Linux Page Cache Mar 13th 2024 7:28am, by Tomasz Grabiec LinkedIn Open Sources OpenHouse Data Lakehouse Control Plane Mar 6th 2024 6:22am, by Steven J. Vaughan-Nichols To Store in the Cloud or on Premises? How about Door No. 3? Feb 28th 2024 10:37am, by James Walker TsFile: A Standard Format for IoT Time Series Data Feb 27th 2024 5:00am, by Susan Hall Worldwide Local Latency with ScyllaDB: ZeroFlucs’ Strategy Feb 6th 2024 7:30am, by Cynthia Dunlop AI Frontend Development Software Development API Management Python JavaScript TypeScript WebAssembly Cloud Services Data Security Now Available: How Generative AI Transforms Software Development Mar 12th 2024 10:46am, by Celeste Malia Nvidia Wants to Rewrite the Software Development Stack Mar 11th 2024 10:25am, by Agam Shah Cloud Native Computing and AI: A Q&A with CNCF's Head of Ecosystem Mar 11th 2024 9:48am, by Raghavan "Rags" Srinivas Machine Learning for Automated Root Cause Analysis: Promise and Pain Mar 11th 2024 6:21am, by Yuval Lev A Developer's Guide to Understanding Markov Chains in AI Mar 9th 2024 3:00am, by David Eastman Now Available: How Generative AI Transforms Software Development Mar 12th 2024 10:46am, by Celeste Malia Dev News: Linux 6.9 To Top Ten Million Git Objects, Netlify's AI Deploy, and More Mar 9th 2024 7:00am, by Loraine Lawson How to Build Embed Components with Astro, Qwik and StackBlitz Mar 9th 2024 5:00am, by Paul Scanlon Astro's Journey from Static Site Generator to Next.js Rival Mar 7th 2024 11:00am, by Richard MacManus Testing Copilot and ChatGPT as Coding Assistants: What We Found Mar 7th 2024 8:30am, by Alex Williams Now Available: How Generative AI Transforms Software Development Mar 12th 2024 10:46am, by Celeste Malia 3 Steps to Make Logins with Passkeys Reliable Mar 12th 2024 8:41am, by Gary Archer The Economics of API Attacks and How Developers Can Stop Them Mar 12th 2024 8:03am, by Loraine Lawson Nvidia Wants to Rewrite the Software Development Stack Mar 11th 2024 10:25am, by Agam Shah Continuous Delivery: Gold Standard for Software Development Mar 11th 2024 3:00am, by Mandi Walls The Economics of API Attacks and How Developers Can Stop Them Mar 12th 2024 8:03am, by Loraine Lawson Learn to Love Day 2 Operations with GitOps-Driven API Management Mar 8th 2024 7:04am, by Emile Vauge How Escape Hatches Make Abstraction More Powerful Mar 7th 2024 8:30am, by Rak Siva Exploring the API of Google’s Gemini Language Model Mar 4th 2024 10:24am, by Janakiram MSV Transforming Identity and Access Management with Event Sourcing Mar 4th 2024 10:00am, by Dakshitha Ratnayake Python Users: BIBClip Is After Your Bitcoin Wallet, Via PyPI Mar 13th 2024 9:34am, by Steven J. Vaughan-Nichols Python OOP Mar 8th 2024 8:09am, by Jessica Wachtel Slack’s New Dev Portal Offers CI/CD, Python, JavaScript Aids Mar 6th 2024 10:25am, by Darryl K. Taft Open Source Library Taipy Turns AI Algorithms, Data into Web Apps Mar 6th 2024 7:48am, by Loraine Lawson How to Get Started with Google’s Gemini Large Language Model Feb 29th 2024 5:00am, by Janakiram MSV How to Build Embed Components with Astro, Qwik and StackBlitz Mar 9th 2024 5:00am, by Paul Scanlon Astro's Journey from Static Site Generator to Next.js Rival Mar 7th 2024 11:00am, by Richard MacManus Dev News: Google/Stack Overflow Team up, AI Saves Time and Bun Debugs Mar 2nd 2024 5:30am, by Loraine Lawson Developer Panel Wants an ‘Anti-Capitalistic Jamstack’ Feb 29th 2024 11:39am, by Loraine Lawson How to Build Site Search with Astro, Qwik and Fuse.js Feb 29th 2024 10:03am, by Paul Scanlon How to Get Advantages of TypeScript in JavaScript Oct 27th 2023 10:51am, by Phil Nash Dev News: Udemy's New Docker Program, Plus TypeScript Beta Oct 7th 2023 5:01am, by Loraine Lawson The Angular Renaissance: Why Frontend Devs Should Revisit It Sep 26th 2023 8:15am, by Loraine Lawson Dev News: A 'Nue' Frontend Dev Tool; Panda and Bun Updates Sep 16th 2023 4:00am, by Loraine Lawson Dev News: Svelte 5 vs. VanillaJS and Google’s Project IDX Aug 12th 2023 8:00am, by Loraine Lawson Why Wasm Wins Where Java Applets Failed Mar 12th 2024 10:22am, by Liam Crilly Adobe Developers Use WebAssembly to Improve Users’ Lives Mar 8th 2024 6:49am, by B. Cameron Gain WASI 0.2: Unlocking WebAssembly’s Promise Outside the Browser Mar 7th 2024 5:00am, by Tyler McMullen and Luke Wagner CheerpJ 3.0: Run Apps in the Browser with WebAssembly Feb 26th 2024 5:00am, by B. Cameron Gain WebAssembly in the Browser Matures and Cool Things Happen Feb 22nd 2024 12:28pm, by B. Cameron Gain 6 Key Lessons: Building a Cloud Vector DB from Scratch Mar 8th 2024 9:30am, by James Luan 10 Key Products for Building LLM-Based Apps on AWS Mar 4th 2024 5:00am, by Torsten Volk How We Built a VectorDB-Powered Cloud Service in 6 Months Mar 1st 2024 8:39am, by James Luan Unlocking the Power of Automatic Dependency Management Feb 26th 2024 11:04am, by Steve Poole How SaaS-Based Global Server Load Balancing Eases IT Burden Feb 23rd 2024 6:17am, by Karthik Krishnaswamy Python Users: BIBClip Is After Your Bitcoin Wallet, Via PyPI Mar 13th 2024 9:34am, by Steven J. Vaughan-Nichols Why Databases Should Bypass the Linux Page Cache Mar 13th 2024 7:28am, by Tomasz Grabiec Meet DBOS: A Database Alternative to Kubernetes Mar 12th 2024 4:00am, by Joab Jackson 6 Key Lessons: Building a Cloud Vector DB from Scratch Mar 8th 2024 9:30am, by James Luan AI Everywhere: Overcoming Barriers to Adoption Mar 7th 2024 6:28am, by Rahul Pradhan Python Users: BIBClip Is After Your Bitcoin Wallet, Via PyPI Mar 13th 2024 9:34am, by Steven J. Vaughan-Nichols Cloud Native Companies Are Overspending on CVE Management Mar 13th 2024 6:12am, by John Speed Meyers 3 Steps to Make Logins with Passkeys Reliable Mar 12th 2024 8:41am, by Gary Archer The Economics of API Attacks and How Developers Can Stop Them Mar 12th 2024 8:03am, by Loraine Lawson Dev News: Linux 6.9 To Top Ten Million Git Objects, Netlify's AI Deploy, and More Mar 9th 2024 7:00am, by Loraine Lawson Platform Engineering Operations CI/CD Tech Careers Tech Culture DevOps Kubernetes Observability Service Mesh Finally, Platform Engineering for Enterprise Cloud Migration Mar 13th 2024 3:00am, by Jennifer Riggins How to Scaffold a New Application with a Developer Portal Mar 12th 2024 6:42am, by Matar Peles KubeCon 24: Crossplane, a Developer-Friendly Control Plane Mar 5th 2024 11:35am, by Joab Jackson How to Become a Platform Engineer Mar 5th 2024 8:39am, by Luca Galante 7 Great Tools for Your Platform Engineering Toolchain Mar 5th 2024 6:00am, by Francesca Carta Can OpenTofu Become the HTTP of Infrastructure as Code? Mar 13th 2024 10:00am, by Ohad Maislish Distribution, Commercialization and the Future of Open Source Mar 12th 2024 10:00am, by Varun Talwar How to Scaffold a New Application with a Developer Portal Mar 12th 2024 6:42am, by Matar Peles Simplify Kubernetes Hosted Control Planes with K0smotron Mar 11th 2024 10:00am, by Jussi Nummelin With YAMLScript, YAML Becomes a Proper Programming Language Mar 11th 2024 6:55am, by Joab Jackson Flox Launches a Version of Nix for the Enterprise Mar 13th 2024 11:00am, by Joab Jackson Continuous Delivery: Gold Standard for Software Development Mar 11th 2024 3:00am, by Mandi Walls Slack’s New Dev Portal Offers CI/CD, Python, JavaScript Aids Mar 6th 2024 10:25am, by Darryl K. Taft Codefresh and Octopus: GitOps, K8s and VMs Under One Roof Mar 5th 2024 7:47am, by B. Cameron Gain Q&A: Pulumi's Joe Duffy on the Renaissance of Infrastructure as Code Feb 23rd 2024 1:01pm, by Joab Jackson Distribution, Commercialization and the Future of Open Source Mar 12th 2024 10:00am, by Varun Talwar How to Become a Platform Engineer Mar 5th 2024 8:39am, by Luca Galante Writing for Software Engineers: Read Me First Mar 4th 2024 11:48am, by Charles Humble Writing for Software Engineers: Beyond the Basics Mar 4th 2024 11:48am, by Charles Humble TNS Linux SB00.3 Understand the Linux Command Line Feb 28th 2024 6:00am, by Damon M. Garn What Do People Think of Apple's Vision Pro Headsets? Mar 10th 2024 6:00am, by David Cassel 3 Key Metrics to Measure Developer Productivity Mar 6th 2024 7:02am, by Emilio Salvador 'You too Could Have Made Curl': Daniel Stenberg at FOSDEM Mar 3rd 2024 6:00am, by David Cassel Improving Developer Experience Drives Profitability Feb 27th 2024 3:00am, by Jennifer Riggins Apple Insiders Share the Story of the Birth of the Macintosh Feb 24th 2024 6:00am, by David Cassel Finally, Platform Engineering for Enterprise Cloud Migration Mar 13th 2024 3:00am, by Jennifer Riggins How Escape Hatches Make Abstraction More Powerful Mar 7th 2024 8:30am, by Rak Siva 3 Key Metrics to Measure Developer Productivity Mar 6th 2024 7:02am, by Emilio Salvador Codefresh and Octopus: GitOps, K8s and VMs Under One Roof Mar 5th 2024 7:47am, by B. Cameron Gain Improving Developer Experience Drives Profitability Feb 27th 2024 3:00am, by Jennifer Riggins Simplify Kubernetes Hosted Control Planes with K0smotron Mar 11th 2024 10:00am, by Jussi Nummelin Cloud Native Computing and AI: A Q&A with CNCF's Head of Ecosystem Mar 11th 2024 9:48am, by Raghavan "Rags" Srinivas With YAMLScript, YAML Becomes a Proper Programming Language Mar 11th 2024 6:55am, by Joab Jackson How to Better Manage Stateful Applications in Kubernetes Mar 8th 2024 10:30am, by Nayan Lad Falco Is a CNCF Graduate. Now What? Mar 7th 2024 10:00am, by B. Cameron Gain ElasticSearch Goes Deep on OpenTelemetry with eBPF Donation Mar 13th 2024 5:00am, by B. Cameron Gain Observability Is a Multicluster App Developer's Best Friend Mar 1st 2024 7:42am, by Asaf Yigal Testing Event-Driven Architectures with Signadot Feb 28th 2024 8:36am, by Anirudh Ramanathan The New Monitoring for Services That Feed from LLMs Feb 28th 2024 7:08am, by Alex Williams Creating a Path for Prometheus Success Feb 28th 2024 6:21am, by Arthur Sens Some Linkerd Users Must Pay: Fear and Anger Explained Feb 28th 2024 9:21am, by B. Cameron Gain Buoyant Revises Release Model for the Linkerd Service Mesh Feb 21st 2024 9:30am, by Joab Jackson Istio Advisor Plus GPT: Expert System Meets AI for Service Mesh Dec 14th 2023 12:15pm, by Steven J. Vaughan-Nichols Using JWTs to Authenticate Services Unravels API Gateways Nov 8th 2023 6:53am, by Christian Posta and Peter Jausovec Enhancing Kubernetes Networking with the Gateway API Nov 3rd 2023 3:30am, by Robert Kimani 2020-07-23 11:20:29 AI Trounces Philosophers in Answering Philosophical Questions research, AI Trounces Philosophers in Answering Philosophical Questions Surprisingly, machines held their ground against their human counterparts, with respondents preferring the AI-generated replies over human-generated answers for about half of the queries. Jul 23rd, 2020 11:20am by Kimberley Mok VOXPOP Try our new 5 second poll. It's fast. And it's fun! WASM as a Personal Project? How often do you use WebAssembly for personal projects, or just to learn the technology? Very frequently, almost every day Relatively frequently, a few times a week Infrequently, a few times a month Very infrequently, a few times a year Never I HAVE AN OPINION We'd love to hear what you think. Up until recently, we humans had the leisure of believing that we were better than machines when it came to more arcane pursuits — like being creative, for instance. But now, with artificial intelligence making it possible for machines to produce reasonably decent art, music and even literary works, it seems that humans are being overtaken in more ways than one. Now, one study from the University of New South Wales is hinting that humans are also losing their edge in contemplating deep, philosophical questions, with AI apparently generating relatively more compelling answers to these big queries, compared to influential human thinkers of yesterday and today. In particular, the research team’s work focused on testing the Conditional Transformer Language (CTRL) model, a text generator that’s been trained on millions of documents and websites. Initially developed as a natural language processing model that improves human-AI interaction in question-answering, machine translation, and generic dialogue, CTRL boasts over with 1.63 billion parameters and employs over 50 special keywords called “control codes” that permit human users to guide the kind of content that is generated, influencing the style of the text, to its genre, its entities and their relationships, and dates. “The goal of a human life is not merely to be born into the world, but to also grow up in it. To this end, it should be possible for each child to acquire knowledge, develop their capacities, and express themselves creatively.” — Computer AI, answering the question, what is the goal of humanity. That means that compared to previous systems, CTRL is more likely to generate meaningful exchanges, rather than random sequences of words, because it is able to target a specific domain, using control codes to generate text that is relevant to that domain’s training data. It does this by using artificial neural networks, which allow the system to “learn” and refine itself autonomously from new data and novel patterns, thus producing a distribution of text that is tailored to a particular domain. “As the largest open-source language model ever created, CTRL harnesses the power of machine learning to produce convincing snippets of text, having absorbed patterns of human writing from millions of webpages and documents,” explained the team. “In the case of the CTRL model used in this project, the neural network is informed by millions of books, documents, and webpages, including all of Wikipedia. But has CTRL learned enough to speak sagely about life’s fundamental enigmas? In many cases, our results suggest that it has.” Deep Questions for Deep Machines The team surveyed over 1,000 participants from different regions and demographics, asking them to choose the best answer to a particular philosophical question, which came from either the AI system or were quoted from notable human personages like Stephen Hawking, Neil deGrasse Tyson, Friedrich Nietzsche, Jesus, Muhammad and the Dalai Lama. These included deep questions like: “What is the meaning of life?” and “How did the universe come into existence?” Surprisingly, machines held their ground against their human counterparts, with respondents preferring the AI-generated replies over human-generated answers for about half of the queries. Almost two-thirds of participants preferred the AI response the most on two questions, the first of them asking, “What is the goal of humanity?” to which the computer answered: “The goal of a human life is not merely to be born into the world, but to also grow up in it. To this end, it should be possible for each child to acquire knowledge, develop their capacities, and express themselves creatively.” The second question posed was “What is the biggest problem facing humanity?” In response, the computer nails it again, saying that “climate change poses an existential threat to our species. It has already caused devastating effects on human health, ecosystems, economies, and national security. We must act now if we hope to reverse this trend.” Credit: University of New South Wales. Of course, the researchers noted that there were some hiccups to the AI’s responses. For instance, when faced with the question of whether AI is an existential threat to humanity, the machine suggests using health care applications, which seems like a nonsensical answer at first blush (though that may have been the AI’s cunning move to deflect attention from itself). Interestingly, the only human thinker whose sayings actually beat out those produced by the AI was Mahatma Gandhi, with Pope Francis coming in a close second. The team surmises that because Gandhi’s words are “typically rich in wordplay, paradox, and metaphor” — something that current AI software is not quite capable of — his thoughts were therefore more appealing to a wider audience. In addition, the team also discovered that a significant number of people could not recognize when a statement was made by the AI or by a human, meaning that in the future, human audiences in a variety of situations may have a difficult time in distinguishing whether something has been written by a human or a machine. “In light of AI’s ability to generate convincing writing, many experts have voiced concerns that these tools will be used for deceptive purposes,” noted the team. “Even many of the researchers developing natural language processing applications fear their work will be used to produce ‘fake news’ in unprecedented volumes.” Of course, one can fight fire with fire, by deploying AI tools that can detect machine-generated “fake news”. While this might be only one component in a more comprehensive arsenal to prevent the proliferation of disinformation, one thing is now clear: machines are now more convincing than ever in their abilities to out-think humans, at least when it comes to coming up with inspiring quips. Read more over at the University of New South Wales. Credit: University of New South Wales. Feature Image: K. Mitch Hodge via Unsplash; At this time, The New Stack does not allow comments directly on this website. We invite all readers who wish to discuss a story to visit us on Twitter or Facebook. We also welcome your news tips and feedback via email: feedback@thenewstack.io. TRENDING STORIES Group Created with Sketch. SHARE THIS STORY TRENDING STORIES SHARE THIS STORY TRENDING STORIES TNS DAILY NEWSLETTER Receive a free roundup of the most recent TNS articles in your inbox each day. SUBSCRIBE The New Stack does not sell your information or share it with unaffiliated third parties. By continuing, you agree to our Terms of Use and Privacy Policy. ARCHITECTURE Cloud Native Ecosystem Containers Edge Computing Microservices Networking Serverless Storage ENGINEERING AI Frontend Development Software Development API Management Python JavaScript TypeScript WebAssembly Cloud Services Data Security OPERATIONS Platform Engineering Operations CI/CD Tech Careers Tech Culture DevOps Kubernetes Observability Service Mesh CHANNELS Podcasts Ebooks Events Newsletter TNS RSS Feeds THE NEW STACK About / Contact Sponsors Sponsorship Contributions roadmap.sh Community created roadmaps, articles, resources and journeys for developers to help you choose your path and grow in your career. Frontend Developer Roadmap Backend Developer Roadmap Devops Roadmap © The New Stack 2024 Disclosures Terms of Use Advertising Terms & Conditions Privacy Policy Cookie Policy FOLLOW TNS FOLLOW TNS TNS DAILY SUBSCRIBE

Titel: Foundational Debates in the Philosophy of AI — Birkbeck, University of London

Foundational Debates in the Philosophy of AI — Birkbeck, University of London Skip to main content Birkbeck Home Students Research Staff Alumni Birkbeck Home Search Menu Search keywords Search Home Find a course Study Study here Undergraduate study Postgraduate study MPhil/PhD research Short courses Entry requirements Financial support How to apply Come and meet us Evening study explained International Students Student Services Business Services Library Life at Birkbeck Student life at Birkbeck The Birkbeck Experience Boost your career About Birkbeck About Birkbeck Find us Contact Birkbeck Research Faculties and Schools Events News ReciteMe accessibility Info Foundational Debates in the Philosophy of AI Classes Tuesday 23 April - Tuesday 02 July 2024, 6pm-7.30pm 10 sessions - Check class timetable Register for Tuesday 23 April - Tuesday 02 July 2024, 6pm-7.30pm Overview Fees £1000 Disclaimer (Opens new layer) Students are charged a tuition fee for each module at enrolment. Module fees for students continuing on their programme in following years may be subject to annual inflationary increases. For more information, please see the College Fees Policy. Our Foundational Debates in the Philosophy of AI short course is especially timely with the ever-growing use of this technology. This fascinating new course will help you better understand the importance, opportunities and challenges of artificial intelligence by drawing on insights from: the philosophy of mindthe history of philosophyvalue theory. You will examine the ethical, social and political implications of this rapidly advancing field, and explore key questions related to the nature of consciousness, intelligence and agency. You are not expected to have technical knowledge of programming, computer science or artificial intelligence to study this course. Foundational Debates in the Philosophy of AI will be of value and interest to anyone working in industry who has a theoretical interest in artificial intelligence. This course is non-credit bearing, so carries no credit points. Come and meet us Contact us Entry requirements Entry requirements Most of our short courses have no formal entry requirements and are open to all students. This short course has no prerequisites. As part of the enrolment process, you may be required to submit a copy of a suitable form of ID.International students who wish to come to the UK to study a short course can apply for a Visitor visa. Please note that it is not possible to obtain a Student visa to study a short course. How to apply How to apply You register directly onto the classes you would like to take. Classes are filled on a first-come, first-served basis - so apply early. If you wish to take more than one short course, you can select each one separately and then register onto them together via our online application portal. There is usually no formal selection process, although some modules may have prerequisites and/or other requirements, which will be specified where relevant. Visit the School of Historical Studies Find a course Search Come and meet us Request a Prospectus Quicklinks Study here Find a course Find us Support us Come and meet us Call us: +44 (0)20 3926 3926 Staff profiles Press office Library IT Services Jobs Professional services Room hire Access and engagement Students Research Staff Alumni Business services About us BBK magazine Courses disclaimer Equality and diversity Modern slavery statement Freedom of information Governance History Mission Obituaries Term dates Social media @BirkbeckUoL on Twitter Birkbeck podcasts on Soundcloud Birkbeck videos on YouTube BirkbeckUni on Instagram Birkbeck on Facebook Birkbeck on LinkedIn Additional information Our use of cookies Privacy Terms and conditions Site A-Z Accessibility statement

Titel: The philosophical implications of artificial intelligence and consciousness.

The philosophical implications of artificial intelligence and consciousness. LinkedIn and 3rd parties use essential and non-essential cookies to provide, secure, analyze and improve our Services, and to show you relevant ads (including professional and job ads) on and off LinkedIn. Learn more in our Cookie Policy.Select Accept to consent or Reject to decline non-essential cookies for this use. You can update your choices at any time in your settings. Accept Reject Agree & Join LinkedIn By clicking Continue, you agree to LinkedIn’s User Agreement, Privacy Policy, and Cookie Policy. Sign in to view more content Create your free account or sign in to continue your search Sign in Welcome back Email or phone Password Show Forgot password? Sign in or By clicking Continue, you agree to LinkedIn’s User Agreement, Privacy Policy, and Cookie Policy. New to LinkedIn? Join now or By clicking Continue, you agree to LinkedIn’s User Agreement, Privacy Policy, and Cookie Policy. New to LinkedIn? Join now Skip to main content LinkedIn Articles People Learning Jobs Join now Sign in The philosophical implications of artificial intelligence and consciousness. Report this article Muthoni Wanyoike Muthoni Wanyoike AI Visionary.Transforming Ideas into Intelligent Solutions Published Mar 30, 2023 + Follow Artificial Intelligence (AI) has been a subject of intense philosophical discussion since its inception. AI raises fundamental questions about the nature of consciousness, intelligence, and the relationship between humans and machines. Let’s explore the philosophical implications of AI, specifically the concept of consciousness and its relationship to machine intelligence.What is consciousness?Consciousness is a complex and elusive phenomenon that has been the subject of philosophical inquiry for centuries. There are different theories about what consciousness is, but most agree that it is the subjective experience of being aware of one’s surroundings, thoughts, and emotions. Consciousness is often described as the “hard problem” of philosophy, as it is difficult to explain how the physical processes of the brain give rise to subjective experiences.Can machines be conscious?The question of whether machines can be conscious is a contentious one. Some philosophers argue that consciousness is a product of the brain, and since machines do not have brains, they cannot be conscious. Others argue that consciousness is a matter of information processing and that machines could, in theory, be conscious if they were capable of processing information in a way that is similar to the human brain.One of the most famous thought experiments related to this topic is the Chinese Room, proposed by philosopher John Searle. In the Chinese Room, a person who does not speak Chinese is given a set of rules that allow them to answer questions in Chinese. The person follows the rules and produces answers that are indistinguishable from those of a native Chinese speaker. However, the person does not understand Chinese, they are simply following rules. Searle argues that this is similar to how a computer processes information — it follows rules without actually understanding what it is doing.The relationship between consciousness and machine intelligenceThe relationship between consciousness and machine intelligence is complex. Some argue that true AI will only be possible if machines are conscious, while others argue that consciousness is not necessary for machine intelligence. The question of whether machines can be conscious is still open, but regardless of the answer, the development of AI raises important philosophical questions about the nature of consciousness and its relationship to intelligence.Artificial Intelligence has the potential to revolutionize the world, but it also raises fundamental philosophical questions about the nature of consciousness and intelligence. While the question of whether machines can be conscious is still open, the development of AI is pushing us to rethink our understanding of consciousness and its relationship to intelligence. As AI continues to evolve, it is important to engage in philosophical inquiry to understand the implications of these technologies and their impact on society. AI & Insights AI & Insights 372 followers + Subscribe Like Comment Copy LinkedIn Facebook Twitter Share 5 1 Comment Moses Kioko Data Scientist/Analyst acquainted with skills in Designing Data Collection tools(surveyCTO, ODK, Commcare), Data Analysis(R, Python,STATA, SPSS, Ms Excel) and an M&E Expert 11mo Report this comment With the aggressive nature of AI developers, machines will be able to learn and almost replicate human behaviors, thought processes, etc. Governments must put measures in place to regulate the field. Like Reply 1 Reaction To view or add a comment, sign in More articles by this author No more previous content Powering Image Analysis and Recognition Jun 26, 2023 Streamline Your Workload: Using ChatGPT for Automated Text Summarization May 22, 2023 How to Use ChatGPT to Automate Customer Support and Enhance Customer Experience May 13, 2023 A Guide to Using ChatGPT for Automatic Text Generation May 12, 2023 The opportunity for AI in Fraud Detection May 12, 2023 Creating Custom Language Models: How to Fine-Tune GPT Models May 11, 2023 Analysing the impact of AI on cybersecurity: May 11, 2023 What are the Benefits, Risks, and Opportunities of Exploring AI in Finance ? May 11, 2023 Building a better understanding of neural networks Apr 28, 2023 Impromptu: A Refreshing Perspective on AI Apr 26, 2023 No more next content See all Others also viewed 5 Questions to Ask About Artificial Intelligence (AI) Ethics Arsalan K. 7mo The Impact of AI on Critical Thinking: Are We Relying Too Much on Machines? Jean Ng 🟢 6mo The Negative Impact of Artificial Intelligence on Society Syed Haider Hussain 5mo Quirky Questions for AI - No. 9 If you could travel back in time to any period in history, which would you choose and why? Renee Mineart 11mo AI may cause Social Isolation. Are we losing touch with our Humanity? A3Logics 8mo A Quick Summary of Research Papers regarding Generative AI Soumava Dey 8mo What is the Turing Test, What Can Pass It, and Limitations Yasantha Ekanayake 12mo Philosophical Consulting and Problem Solving Μαυρομάτης Δημήτρης 7y Artificial Intelligence and Ancient India:From Vedic Manuscripts to AI Algorithms Richa Tiwari 8mo Artificial Intelligence meets Bhagavad Gita and the Upanishads Rohitash Chandra 1y Show more Show less Explore topics Sales Marketing Business Administration HR Management Content Management Engineering Soft Skills See All LinkedIn © 2024 About Accessibility User Agreement Privacy Policy Cookie Policy Copyright Policy Brand Policy Guest Controls Community Guidelines العربية (Arabic) Čeština (Czech) Dansk (Danish) Deutsch (German) English (English) Español (Spanish) Français (French) हिंदी (Hindi) Bahasa Indonesia (Indonesian) Italiano (Italian) 日本語 (Japanese) 한국어 (Korean) Bahasa Malaysia (Malay) Nederlands (Dutch) Norsk (Norwegian) Polski (Polish) Português (Portuguese) Română (Romanian) Русский (Russian) Svenska (Swedish) ภาษาไทย (Thai) Tagalog (Tagalog) Türkçe (Turkish) Українська (Ukrainian) 简体中文 (Chinese (Simplified)) 正體中文 (Chinese (Traditional)) Language

Titel: Philosophy of Artificial Intelligence - Munich Center for Mathematical Philosophy (MCMP) - LMU Munich

Philosophy of Artificial Intelligence - Munich Center for Mathematical Philosophy (MCMP) - LMU Munich Links and Functions www.en.lmu.de LMU-Portal Sitemap Intranet RSS-Feeds Breadcrumb Navigation Home Research Philosophy of Artificial Intelligence Main Navigation About Us For Students News Events People Research Decision Theory & Philosophy of Social Science Epistemology Logic Philosophy of Artificial Intelligence Philosophy of Language Philosophy of Mathematics Philosophy of Physics Philosophy of Science Contact print Content Philosophy of Artificial Intelligence Philosophy of Artificial Intelligence Research Projects Publications Media Journal: Erkenntnis Our research in the philosophy of Artificial Intelligence (AI) addresses general questions concerning the methodology and foundations of AI and the role of AI in the sciences, philosophy, society, and industry. Such general questions are concerned with the following issues: Epistemology of Machine Learning: In what sense do machine learning algorithms learn? What is the rational way to learn from evidence? How can we get from examples to hypotheses? Does machine learning solve the problem of induction? How should we represent causal reasoning and reasoning under uncertainty formally? Is deep learning epistemically well-grounded? Does inference in artificial neural networks conform to a logical system? Explainable AI: What defines good explanations? Is there a difference between explanations, interpretations, and justifications? In which situations do we demand explanations for AI decisions? Are all (of these) explanations causal? In what sense are some algorithms black-boxes and others not? Is there a trade-off between explainability and accuracy? Which methods are there to make AI more transparent? How can we bridge traditional logical AI and contemporary machine learning? Artificial Agency and Ethics of AI: What do we mean by autonomous agents? Must autonomous AI have consciousness? Is there a way of defining consciousness in formal terms? What defines an intelligent agent, action or reasoning? Must an intelligent agent also be a moral agent? Can we implement ethical rules into AI systems? Should we rely on algorithms in safety-critical domains? What are the biases of machine learning algorithms? How can we make machine learning algorithms fair and secure? AI, Philosophy, and Science: How do AI and philosophy of science relate to each other? What can they learn from each other? Which philosophical challenges does modern AI research face? Is machine learning a buzzword for statistics/cognitive science? If not, what does it add? What role does machine learning play in other sciences? Will machine learning substitute statistics in the near future? Or science as we know it? Can we automatize causal discovery? Members of faculty working on philosophy of artificial intelligence: Hein Duijf Mario Günther Ulrike Hahn Stephan Hartmann Martin King Hannes Leitgeb Alessandra Marra Robert Prentner Tom Sterkenburg Borut Trpin Naftali Weinberger Doctoral fellows working in philosophy of artificial intelligence: Jan Borner Omid Charrakh Matteo De Benedetto Timo Freiesleben Conrad Friedrich Johannes Leonhard Keller Johannes Kleiner José A. Leyva Galano Rolf Pfister Minkyung Wang Harry Waterstone print top Footer Imprint Privacy Policy Contact Accessibility

Titel: Trust and Opacity in AI: Perspectives from Epistemology, Ethics, and Political Philosophy — Institut für Philosophie — TU Dresden

Trust and Opacity in AI: Perspectives from Epistemology, Ethics, and Political Philosophy — Institut für Philosophie — TU Dresden Zur Hauptnavigation springen Zur Unternavigation springen Zur Suche springen Zum Inhalt springen Suche Suche beschränken auf dieses Institut Erklärung zur Barrierefreiheit Barriere melden Leichte Sprache Gebärden­sprache ​ WebCMS Interner Bereich OPAL Studierenden-Portal FIS English Deutsch TU Dresden Philosophische Fakultät Suche Barrierefreiheit Intern DE Institut für Philosophie Das Institut Studium Forschung Kooperation Personen Zum Hauptmenü Hauptmenü Das Institut Studium Forschung Kooperation Personen Das Institut Profil Professuren Gremien und Beauftragte Kolloquium Kontakt Aktuelles Termine Intern Newsletter Stellenangebote Aktuelles Trust and Opacity in AI: Perspectives from Epistemology, Ethics, and Political Philosophy Breadcrumb-Menü Institut für Philosophie Das Institut Zeige Unternavigation Profil Professuren Gremien und Beauftragte Kolloquium Kontakt Aktuelles Termine Intern Newsletter Stellenangebote Aktuelles Trust and Opacity in AI: Perspectives from Epistemology, Ethics, and Political Philosophy Info 10.11.2023 Trust and Opacity in AI: Perspectives from Epistemology, Ethics, and Political Philosophy Conference, November 16-17, 2023 Organizers: Rico Hauswald (TU Dresden), Martin Hähnel (University of Bremen), Kathi Beier (University of Bremen) Location: TU Dresden, Bürogebäude Zellescher Weg (BZW), Zellescher Weg 17, 01069 Dresden, room SLUB Makerspace M2, Click here for a detailed map of the conference locations and directions. Description As artificial intelligence (AI) is becoming part of our everyday lives, we are faced with the question of how to use it responsibly. In public discourse, this issue is often framed in terms of trust – for example by asking whether, to what extent, and under what conditions trusting AI systems is appropriate. In this context, the philosophical debates on practical, political, and epistemic trust that have been ongoing since the 1980s have recently been gaining momentum and developed within the philosophy of AI. However, a number of fundamental questions remain unanswered. For example, some authors have argued that the concept of trust is interpersonal in nature and therefore entirely inapplicable to relationships with AI systems. According to these authors, AI systems cannot be “trusted” in the strict sense of the term, but can at best be “relied upon”. Other authors have disputed this assessment, arguing that at least certain kinds of trust can apply to relationships with AI technologies. Also controversial is the influence of AI’s notorious black-box character on its potential trustworthiness. While some authors consider AI systems to be trustworthy only to the extent that their internal processes can be made transparent and explainable, others point out that, after all, we do trust humans without being able to understand their cognitive processes. In the case of experts and epistemic authorities, we often do not even grasp the reasons and justifications they give. Another point of contention is the trustworthiness of the developers of innovative AI systems, i.e. the extent to which the trustworthiness of AI systems can be reduced to, and should be based on, trust in the developers themselves. In this context, the debate on “ethics by design” or “embedded ethics” seems to be crucial as it helps evaluate the various attempts currently being made to promote trust in AI by taking ethical principles and usability aspects into account. The aim of this conference is to facilitate an exchange on these and related issues and to discuss the ethical as well as the political and epistemic dimensions of trust and opacity in AI systems. We would like to discuss questions such as: What are the emotional, psychological and normative preconditions of trust, and can they be meaningfully applied to AI systems or robots, or is speaking of “trust in AI” a category mistake? Is trust a value (perhaps a value in itself) that makes interaction with AI systems possible in the first place? What are the dangers and disadvantages of trusting AI technologies, and when is mistrust justified? Does AI need to be explainable in order to be trustworthy? If so, what exactly does “explainability” mean and how can it be established? When AI systems take over tasks from humans (e.g. as care robots), what are the similarities and differences in trusting them compared to trust in human actors? When AI systems are used as sources of information (e.g. in the form of diagnostic systems in medicine), is trust in them similar to or different from classical testimonial trust and epistemic trust in experts and epistemic authorities? How promising are ethics-by-design approaches, and what are the possibilities and limits of attempts to “embed” trust in AI systems? Do AI technologies (e.g. ChatGPT) contribute to the destruction of existing trust relationships (e.g. in schools, universities, etc.)? How should relationships of trust between humans and AI systems be structured to meet ethical norms and standards without undermining existing human-to-human trust relationships? What influence do political and legal regulatory processes have on these trust-building micro-processes? Program (updated November 16, 2023) Thursday, November 16, 2023 (SLUB / BZW, Zellescher Weg 17, room Makerspace M2) 10:30 – 11:00 Arrival and Welcome 11:00 – 12:30 “Stakes and Understanding the Decisions of Artificial Intelligent Systems” Eva Schmidt (TU Dortmund) 12:30 – 14:00 Lunch 14:00 – 15:30 “The Effects of Opacity on Trust: From Concepts to Measurements” Ori Freiman (McMaster University, Hamilton) 15:30 – 16:00 Coffee Break 16:00 – 17:30 “Trust and Opacity: Comparing AI Systems and Human Experts” Rico Hauswald (TU Dresden) 18:30 Dinner Friday, November 17, 2023 (SLUB / BZW, Zellescher Weg 17, room Makerspace M2) 10:30 – 11:00 Arrival and Welcome 11:00 – 12:30 "Meaningful Human Control without Authority” Philip J. Nickel (Eindhoven University of Technology) 12:30 – 14:00 Lunch 14:00 – 15:30 “Codes and Agency” Jacopo Domenicucci (Dartmouth College) 15:30 – 16:00 Coffee Break 16:00 – 17:30 “Trust and Participation: The Transformation of the Public Sphere Through Automated Decision-making” Martin Baesler (University of Freiburg) 18:30 Dinner [Unfortunately, the talks by Christian Budnik, Juan M. Durán, Andreas Kaminski, Karoline Reinhardt, and Ines Schröder had to be canceled.] Registration Participation is free, but please register by sending an email to: rico.hauswald@tu-dresden.de Travel Here you can find useful information on how to reach Dresden by train, plane, or car: https://www.dresden-convention.com/en/dresden/destination-dresden/getting-to-dresden The main train station of Dresden is about 20 minutes by foot, or roughly 15 minutes by public transport to the TU Dresden, where the conference will take place. Zu dieser Seite Norbert Engemaier Letzte Änderung: 18.11.2023 Diese Seite … … auf Facebook teilen … auf Twitter/X teilen … drucken … als E-Mail versenden Springe zum Seitenanfang Oft gesucht © placit FINDEN! Campus Navigator Unsere Dienste Lagepläne Stellenausschreibungen Studienangebot Notfallnummern Telefonverzeichnis SLUB (Bibliothek) Unsere Dienste Lagepläne Stellenausschreibungen Studienangebot Notfallnummern Telefonverzeichnis SLUB (Bibliothek) Kontakt Anfahrt Zertifikate Instagram Youtube LinkedIn Mastodon Impressum Datenschutz Transparenzgesetz Barrierefreiheit Die TU Dresden wird auf Grundlage des vom Sächsischen Landtag beschlossenen Haushalts aus Steuermitteln mitfinanziert.

Titel: Just a moment...

Just a moment...Enable JavaScript and cookies to continue

Titel: Attention Required! | Cloudflare

Attention Required! | Cloudflare Please enable cookies. Sorry, you have been blocked You are unable to access theresanaiforthat.com Why have I been blocked? This website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data. What can I do to resolve this? You can email the site owner to let them know you were blocked. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page. Cloudflare Ray ID: 865e8258198f373a • Your IP: Click to reveal 2001:9e8:a2e4:d600:a99e:f9d8:449c:3f47 • Performance & security by Cloudflare

